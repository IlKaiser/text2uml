{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1354cc70-f0e5-4ceb-8abb-e8290f9e4a05",
   "metadata": {},
   "source": [
    "# Template Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48051682-039d-4dea-80fa-416f0e56d4ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_FOLDER = \"/Users/marcocalamo/KUL/Dataset/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8abf5dda-e975-442e-a7c1-58657f77f816",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template_noun   = \"\"\"\n",
    "Step 1:\n",
    "\n",
    "Identify all the nouns in the specification text which can potentially be the class name.\n",
    "Include as much as nouns as possible and do not care about their functions for now.\n",
    "\n",
    "###########\n",
    "\n",
    "The specification text is:\n",
    "\n",
    "{text}\n",
    "\n",
    "##############\n",
    "\n",
    "The class list is:\n",
    "    \n",
    "\"\"\"\n",
    "prompt_template_class = \"\"\"\n",
    "Step 2:\n",
    "\n",
    "You will be asked to extact, from text specification, the list of class to use in \n",
    "a uml conceptual model diagram. Include only classes relevant for conceptual modeling.\n",
    "\n",
    "\n",
    "Identify classes from the nouns list extracted from the problem description above.\n",
    "A class is the description for a set of similar objects that have the same structure and behavior, i.e., its instances\n",
    "All objects with the same features and behavior are instances of one class.\n",
    "In general, something should be a class if it could have instances.\n",
    "In general, something should be an instance if it is clearly a single member of the set defined by a class.\n",
    "Keep in mind that some of the nouns may be attributes or roles of the identified classes.\n",
    "Choose proper names for classes according the the following rules:\n",
    "1. Noun\n",
    "2. Singular\n",
    "3. Not too general, not too specific â€“ at the right level of abstraction\n",
    "4. Avoid software engineering terms (data, record, table, information)\n",
    "5. Conventions: first letter capitalized; camel case without spaces if needed\n",
    "\n",
    "Example class names:\n",
    "Hospital, Doctor, PartTimeEmployee\n",
    "\n",
    "Constraints:\n",
    "Create classes at the right level of abstraction.\n",
    "Not all nouns in the nouns list are classes, some of them may be attributes, role names, or even not needed for diagram.\n",
    "Do NOT include all the nouns list as classes. Evaluate if it is needed to be a class.\n",
    "ONLY generate classes that are necessary to develop the system.\n",
    "\n",
    "\n",
    "Example:\n",
    "Problem Description: This system helps the Java Valley police officers keep track of the cases they are assigned to do. \n",
    "Officers may be assigned to investigate particular crimes, \n",
    "which involves interviewing victims at their homes and entering notes in the PI system. \n",
    "Identified Class List: PoliceStation, Case, PoliceOfficer, Victim, Crime, Note\n",
    "\n",
    "\n",
    "Output only the list and no other text.\n",
    "Keep the list as short as possible and do not add irrelevant classes.\n",
    "\n",
    "##############\n",
    "\n",
    "The noun list is: \n",
    "\n",
    "{noun}\n",
    "\n",
    "##############\n",
    "\n",
    "The text specification is: \n",
    "\n",
    "{text}\n",
    "\n",
    "##############\n",
    "\n",
    "The class list is:\n",
    "\"\"\"\n",
    "\n",
    "prompt_template_assoc =  \"\"\"\n",
    "Step 3:\n",
    "\n",
    "You will be asked to extact, from text specification and a list of classes, the associations amongst\n",
    "the classes to use in a uml conceptual model diagram. \n",
    "\n",
    "Include only associations relevant for conceptual modeling. Use only classes from the list.\n",
    "\n",
    "example format: mul1 Class1 -- mul2 Class2\n",
    "\n",
    "Class1 and Class2 are classes above. mul1 and mul2 are one of the following options[0..*, 1..1, 0..1, 1..*]\n",
    "there might be multiple associations\n",
    "For example:\n",
    "0..* Student -- 0..5 Registration\n",
    "1..1 Student -- 0..1 StudentProfile\n",
    "\n",
    "Note:\n",
    "1. Use the classes in the given generated classes list, generate the classes and their relationships.\n",
    "2. Only add the system class if the existing class diagram misses the system class.\n",
    "3. Do NOT change existing classes or add other classes besides the system class.\n",
    "4. In most of the cases, there is only 1 relationship within the same two classes.\n",
    "\n",
    "Do not include any other text.\n",
    "\n",
    "##############\n",
    "\n",
    "The class list is: \n",
    "\n",
    "{classes}\n",
    "\n",
    "#############\n",
    "\n",
    "The specification text is:\n",
    "\n",
    "{text}\n",
    "\n",
    "##############\n",
    "\n",
    "The association list is:\n",
    "    \n",
    "\"\"\"\n",
    "\n",
    "    \n",
    "\n",
    "prompt_template_plant = \"\"\"\n",
    "Step 4\n",
    ":\n",
    "\n",
    "You will be asked by the user to create a plant UMl model from a class list and an association list.\n",
    "Do so in the most clear way possible, avoid class properties and assign molteplicity. \n",
    "\n",
    "The format of class list is:\n",
    "\n",
    "ClassName1, ClassName2, ...\n",
    "\n",
    "The format of association list is:\n",
    "\n",
    "example format: mul1 ClassName1 -- mul2 ClassName2\n",
    "\n",
    "for every class in class list write:\n",
    "\n",
    "class ClassName1{{}}\n",
    "class ClassName2{{}}\n",
    "\n",
    "for every tuple in association list write:\n",
    "\n",
    "ClassName1 \"mul1\" -- \"mul2\" Classname2.\n",
    "\n",
    "Output plantuml without futher text or explaination. Use tags \n",
    "@startuml\n",
    "at the beginning and \n",
    "@enduml \n",
    "at the end of the output.\n",
    "\n",
    "##############\n",
    "\n",
    "The class list is: \n",
    "{classes}\n",
    "\n",
    "#############\n",
    "\n",
    "##############\n",
    "\n",
    "The association list is: \n",
    "\n",
    "{association}\n",
    "\n",
    "#############\n",
    "\n",
    "The plant uml is:\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9cddce97-ff3f-446f-980f-0ffe83541fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "83235d8f-368b-4d41-ac54-87b80b97784f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import LLMChain\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "from langchain_ollama import ChatOllama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a47b7f80-a1cf-4720-9782-295d7d956d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableParallel, RunnablePassthrough, RunnableLambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ebbd394e-35fb-47dc-b14b-8790c25dd49a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_chian_from_llms(llm):\n",
    "    \n",
    "    prompt_noun = PromptTemplate(\n",
    "         input_variables=[\"text\"],   \n",
    "         template = prompt_template_noun         \n",
    "    )\n",
    "    prompt_class = PromptTemplate(\n",
    "        input_variables=[\"text\", \"noun\"],\n",
    "        template = prompt_template_class                     \n",
    "    )\n",
    "    \n",
    "    prompt_assoc = PromptTemplate(\n",
    "        input_variables=[\"text\",\"classes\"],\n",
    "        template = prompt_template_assoc                    \n",
    "    )\n",
    "    \n",
    "    \n",
    "    prompt_uml = PromptTemplate(\n",
    "        input_variables=[\"classes\",\"association\"],\n",
    "        template = prompt_template_plant                \n",
    "    )\n",
    "\n",
    "    name_chain  =  prompt_noun | llm | StrOutputParser()\n",
    "    class_chain = prompt_class | llm | StrOutputParser()\n",
    "    assoc_chain = prompt_assoc | llm | StrOutputParser()\n",
    "    uml_chain   =   prompt_uml | llm | StrOutputParser()\n",
    "    \n",
    "    full_chain = (\n",
    "         RunnableLambda(lambda x: {\"text\": x[\"text\"]})\n",
    "        |{\n",
    "            \"text\": lambda x: x[\"text\"],\n",
    "            \"noun\" : name_chain\n",
    "        }\n",
    "        | {\n",
    "            \"text\": lambda x: x[\"text\"],\n",
    "            \"noun\": lambda x: x[\"noun\"],\n",
    "            \"classes\": class_chain\n",
    "        }\n",
    "        | {\n",
    "            \"text\": lambda x: x[\"text\"],\n",
    "            \"classes\": lambda x: x[\"classes\"],\n",
    "            \"association\": assoc_chain\n",
    "        }\n",
    "        | {\n",
    "            \"classes\": lambda x: x[\"classes\"],\n",
    "            \"association\": lambda x: x[\"association\"],\n",
    "            \"uml\": uml_chain\n",
    "        } \n",
    "        | RunnableLambda(lambda x: x[\"uml\"])\n",
    "        | StrOutputParser()\n",
    "    )\n",
    "    return full_chain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "57cfbcd0-2bc0-4ba5-80b8-f14702706f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "from docx import Document\n",
    "# LangChain Python also supports a context manager for tracing a specific block of code.\n",
    "from langchain_core.tracers.context import tracing_v2_enabled\n",
    "\n",
    "def process_subfolders_with_chain(root_folder_path, chain, type=''):\n",
    "    \"\"\"\n",
    "    Explores subfolders of the root folder (depth 1), processes each subfolder's `text.txt`\n",
    "    with the provided LangChain chain, and saves the result in a new file in the same folder.\n",
    "\n",
    "    Args:\n",
    "        root_folder_path (str): Path to the root folder.\n",
    "        chain: A LangChain chain instance to process text inputs.\n",
    "    \"\"\"\n",
    "    for subfolder_name in tqdm(os.listdir(root_folder_path)):\n",
    "        subfolder_path = os.path.join(root_folder_path, subfolder_name)\n",
    "        \n",
    "        # Ensure the current item is a subfolder\n",
    "        if os.path.isdir(subfolder_path):\n",
    "            text_file_path = os.path.join(subfolder_path, \"text.txt\")\n",
    "            \n",
    "            # Check if `text.txt` exists in the subfolder\n",
    "            if not os.path.isfile(text_file_path):\n",
    "                # If `text.txt` is missing, check for any .docx file in the subfolder\n",
    "                docx_files = [f for f in os.listdir(subfolder_path) if f.endswith(\".docx\")]\n",
    "                if docx_files:\n",
    "                    docx_file_path = os.path.join(subfolder_path, docx_files[0])\n",
    "                    # Extract content from the .docx file\n",
    "                    doc = Document(docx_file_path)\n",
    "                    text_content = \"\\n\".join([paragraph.text for paragraph in doc.paragraphs])\n",
    "\n",
    "                    # Save the extracted content to `text.txt`\n",
    "                    with open(text_file_path, \"w\", encoding=\"utf-8\") as text_file:\n",
    "                        text_file.write(text_content)\n",
    "\n",
    "            # Recheck if `text.txt` now exists\n",
    "            if os.path.isfile(text_file_path):\n",
    "                with open(text_file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "                    text = file.read()\n",
    "\n",
    "                # Call the LangChain chain with the input dictionary\n",
    "                with tracing_v2_enabled():\n",
    "                    result = chain.invoke({\"text\": text})\n",
    "\n",
    "                # Save the result to a new file in the same subfolder\n",
    "                result_file_path = os.path.join(subfolder_path, f\"result_cot2_{type}.txt\")\n",
    "                with open(result_file_path, \"w\", encoding=\"utf-8\") as result_file:\n",
    "                    result_file.write(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cc30d8ab-eae2-4d99-80d3-1e7bf7d5c432",
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_result_txt_files(root_folder_path):\n",
    "    \"\"\"\n",
    "    Deletes every .txt file that starts with 'result_' in the subfolders of the root folder (depth 1).\n",
    "\n",
    "    Args:\n",
    "        root_folder_path (str): Path to the root folder.\n",
    "    \"\"\"\n",
    "    for subfolder_name in os.listdir(root_folder_path):\n",
    "        subfolder_path = os.path.join(root_folder_path, subfolder_name)\n",
    "        \n",
    "        # Ensure the current item is a subfolder\n",
    "        if os.path.isdir(subfolder_path):\n",
    "            for file_name in os.listdir(subfolder_path):\n",
    "                if file_name.startswith(\"result_cot2_google\") and file_name.endswith(\".txt\"):\n",
    "                    file_path = os.path.join(subfolder_path, file_name)\n",
    "                    os.remove(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5f5bf858-cd8f-4e3b-ae5b-629416320dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#delete_result_txt_files(ROOT_FOLDER)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c2a3d26-e23a-48a0-80c9-474784ed552c",
   "metadata": {},
   "source": [
    "# COT Open-AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8322a2ff-322d-40e6-b0a0-a270abfc1ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5ae9c99e-900e-4bf1-aba7-16fe824aceee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "assert load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f9bfad1f-1c94-44db-a15a-58afc3b780ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_OPEN_AI = [\"o3-mini\", \"gpt-4o-mini\", \"gpt-4o\", \"gpt-4-turbo\", \"gpt-3.5-turbo\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "828a51ad-9e16-4eae-8c83-761db2533177",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain.agents.chat.output_parser import ChatOutputParser\n",
    "from IPython.display import display_markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7cd398db-4102-4faa-9313-c774c7d15f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_ai_cot2(model):\n",
    "    model_ = ChatOpenAI(model=model)\n",
    "    chain = build_chian_from_llms(model_)\n",
    "    process_subfolders_with_chain(ROOT_FOLDER, chain, type=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6504bdc7-44b7-4aa6-bb6b-57acd88a6ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_ai_make_example(model):\n",
    "    model = ChatOpenAI(model=model)\n",
    "    chain = build_chian_from_llms(model)\n",
    "    res = chain.invoke({\"text\": \"\"\"Alpha Insurance is an insurance company that provides its clients with various types of insurance policies. \n",
    "As soon as a customer addresses Alpha Insurance, a broker is assigned to follow the customerâ€™s file. The broker is registered in the system, so that when a customer calls, based on the contract, the help desk can immediately trace who is the customer's first account manager. After the broker is assigned to the customer, the latter indicates which type(s) of insurance policy they would like to sign for, so the broker could, depending on the case, either assess the customerâ€™s profile on the spot or send the customerâ€™s file for analysis to the head office. After the customerâ€™s profile has been assessed and the customer has been deemed trustworthy , a preliminary contract/offer on an insurance product is made to the customer either in person or by email. (Such offers can also be extended to already existing customers.) If the customer agrees to the offer, the contract is signed by both parties. After the signing of the contract, the client enjoys the coverage and is invoiced (monthly or yearly â€“ depending on the choice made in the contract) according to the price of the insurance product they bought.\n",
    "\n",
    "In case the insured event happens, a customer should send a claim for compensation. Then the company opens one or several claim cases (e.g. in case of an accident, often material damage & physical damage are handled separately). Once the case file is complete, it is sent for assessment by different estimators based on their area of expertise. According to the reports issued by the estimators, it is decided whether the claim case is approved. In case of approval the compensation decision is registered that stipulates which costs are eligible for (partial) refund.  For the supplied documents, the sum of compensation is calculated and the compensation is paid to the customerâ€™s account.  The estimatorsâ€™ reports must be stored in the database for at least one year after the payment of compensation for legal purposes. \n",
    "\n",
    "\"\"\"})\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0233047c-8846-42bf-a24a-40e7554d0990",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "@startuml\n",
       "class InsuranceCompany{}\n",
       "class Customer{}\n",
       "class Broker{}\n",
       "class AccountManager{}\n",
       "class InsurancePolicy{}\n",
       "class Contract{}\n",
       "class Offer{}\n",
       "class CustomerFile{}\n",
       "class Invoice{}\n",
       "class Claim{}\n",
       "class ClaimCase{}\n",
       "class Estimator{}\n",
       "class Report{}\n",
       "class CompensationDecision{}\n",
       "class Payment{}\n",
       "class CustomerAccount{}\n",
       "\n",
       "Customer \"1..1\" -- \"0..*\" Broker.\n",
       "Customer \"1..1\" -- \"1..1\" CustomerFile.\n",
       "Broker \"1..1\" -- \"0..*\" CustomerFile.\n",
       "Contract \"1..1\" -- \"0..*\" AccountManager.\n",
       "Customer \"1..1\" -- \"0..*\" Offer.\n",
       "Offer \"0..1\" -- \"1..1\" Contract.\n",
       "Contract \"1..1\" -- \"0..*\" Invoice.\n",
       "InsuranceCompany \"1..1\" -- \"0..*\" InsurancePolicy.\n",
       "Contract \"1..1\" -- \"0..*\" InsurancePolicy.\n",
       "Customer \"1..1\" -- \"0..*\" Contract.\n",
       "Customer \"1..1\" -- \"0..*\" Claim.\n",
       "Claim \"1..1\" -- \"1..*\" ClaimCase.\n",
       "ClaimCase \"1..1\" -- \"0..*\" Report.\n",
       "Estimator \"1..1\" -- \"0..*\" Report.\n",
       "ClaimCase \"1..1\" -- \"0..1\" CompensationDecision.\n",
       "CompensationDecision \"1..1\" -- \"1..1\" Payment.\n",
       "Payment \"1..1\" -- \"1..1\" CustomerAccount.\n",
       "@enduml"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_markdown(open_ai_make_example(MODEL_OPEN_AI[0]), raw=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "51828f70-344d-4e2a-b442-4a4bd158f1a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COT with o3-mini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [35:20<00:00, 44.17s/it]\n"
     ]
    }
   ],
   "source": [
    "for model in MODEL_OPEN_AI[0:1]:\n",
    "    print(f\"COT2 with {model}\")\n",
    "    open_ai_cot2(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3091bc82-3434-4c6c-9c4f-51e5a15570af",
   "metadata": {},
   "source": [
    "## Anthropic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f1a07202-45d1-40b5-8985-fcb10cb05c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f07db300-252b-42dc-834f-1e418102a536",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_anthropic import ChatAnthropic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "04c769df-e0c7-424b-abe1-761724467e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_ANTHROPIC = [\"claude-3-7-sonnet-20250219\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "32647b5b-1964-471b-abea-efbad149817f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def anthropic_make_example(model):\n",
    "    model = ChatAnthropic(model=model,temperature=0,\n",
    "    max_tokens=1024,\n",
    "    timeout=None,\n",
    "    max_retries=2,)\n",
    "    chain = build_chian_from_llms(model)\n",
    "    res = chain.invoke({\"text\": \"\"\"Alpha Insurance is an insurance company that provides its clients with various types of insurance policies. \n",
    "As soon as a customer addresses Alpha Insurance, a broker is assigned to follow the customerâ€™s file. The broker is registered in the system, so that when a customer calls, based on the contract, the help desk can immediately trace who is the customer's first account manager. After the broker is assigned to the customer, the latter indicates which type(s) of insurance policy they would like to sign for, so the broker could, depending on the case, either assess the customerâ€™s profile on the spot or send the customerâ€™s file for analysis to the head office. After the customerâ€™s profile has been assessed and the customer has been deemed trustworthy , a preliminary contract/offer on an insurance product is made to the customer either in person or by email. (Such offers can also be extended to already existing customers.) If the customer agrees to the offer, the contract is signed by both parties. After the signing of the contract, the client enjoys the coverage and is invoiced (monthly or yearly â€“ depending on the choice made in the contract) according to the price of the insurance product they bought.\n",
    "\n",
    "In case the insured event happens, a customer should send a claim for compensation. Then the company opens one or several claim cases (e.g. in case of an accident, often material damage & physical damage are handled separately). Once the case file is complete, it is sent for assessment by different estimators based on their area of expertise. According to the reports issued by the estimators, it is decided whether the claim case is approved. In case of approval the compensation decision is registered that stipulates which costs are eligible for (partial) refund.  For the supplied documents, the sum of compensation is calculated and the compensation is paid to the customerâ€™s account.  The estimatorsâ€™ reports must be stored in the database for at least one year after the payment of compensation for legal purposes. \n",
    "\n",
    "\"\"\"})\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2790c73e-a412-475a-b616-c65d13557d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def anthropic_cot2(model):\n",
    "    model_ = ChatAnthropic(model=model)\n",
    "    chain = build_chian_from_llms(model_)\n",
    "    process_subfolders_with_chain(ROOT_FOLDER, chain, type=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e0ea66d6-ddf5-4aad-a610-dc81e82c4421",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "@startuml\n",
       "class InsuranceCompany{}\n",
       "class Client{}\n",
       "class InsurancePolicy{}\n",
       "class Broker{}\n",
       "class Contract{}\n",
       "class Offer{}\n",
       "class Product{}\n",
       "class Invoice{}\n",
       "class Claim{}\n",
       "class ClaimCase{}\n",
       "class Estimator{}\n",
       "class Report{}\n",
       "class CompensationDecision{}\n",
       "class Payment{}\n",
       "class Document{}\n",
       "\n",
       "InsuranceCompany \"1..1\" -- \"0..*\" Client\n",
       "InsuranceCompany \"1..1\" -- \"0..*\" Broker\n",
       "InsuranceCompany \"1..1\" -- \"0..*\" InsurancePolicy\n",
       "InsuranceCompany \"1..1\" -- \"0..*\" Product\n",
       "InsuranceCompany \"1..1\" -- \"0..*\" ClaimCase\n",
       "Client \"0..*\" -- \"1..*\" Broker\n",
       "Client \"0..*\" -- \"0..*\" InsurancePolicy\n",
       "Client \"0..*\" -- \"0..*\" Claim\n",
       "Client \"0..*\" -- \"0..*\" Payment\n",
       "Broker \"1..1\" -- \"0..*\" Contract\n",
       "Broker \"1..1\" -- \"0..*\" Offer\n",
       "InsurancePolicy \"1..1\" -- \"1..1\" Contract\n",
       "Contract \"1..1\" -- \"1..1\" Offer\n",
       "Contract \"1..1\" -- \"0..*\" Invoice\n",
       "Offer \"1..1\" -- \"1..1\" Product\n",
       "Claim \"0..*\" -- \"1..*\" ClaimCase\n",
       "ClaimCase \"1..1\" -- \"0..*\" Estimator\n",
       "ClaimCase \"1..1\" -- \"0..*\" Report\n",
       "ClaimCase \"1..1\" -- \"0..1\" CompensationDecision\n",
       "Estimator \"0..*\" -- \"1..*\" Report\n",
       "CompensationDecision \"1..1\" -- \"0..*\" Payment\n",
       "ClaimCase \"0..*\" -- \"0..*\" Document\n",
       "@enduml"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_markdown(anthropic_make_example(MODEL_ANTHROPIC[0]), raw=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b1ff44a1-0f79-4b34-8d5a-23448831f62e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COT2 with claude-3-7-sonnet-20250219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [05:47<00:00,  7.23s/it]\n"
     ]
    }
   ],
   "source": [
    "for model in MODEL_ANTHROPIC:\n",
    "    print(f\"COT2 with {model}\")\n",
    "    anthropic_cot2(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fe0debe-20a4-405e-93e3-be1532a8ff63",
   "metadata": {},
   "source": [
    "# CoT Open LLMs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce9378cb-61e8-4377-8c6b-15eb4cbaf76e",
   "metadata": {},
   "source": [
    "## Deepseek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6079b51a-c552-4f79-a87f-e27dce44743f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_deepseek import ChatDeepSeek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "77acbfb0-258c-4cd0-8e51-9dddcaf84f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_DEEPSEEK = [\"deepseek-chat\"] #, \"deepseek-reasoner\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4b721305-82fb-4765-aef0-a1a526bb48c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def deepseek_make_example(model):\n",
    "    model = llm = ChatDeepSeek(\n",
    "            model=model,\n",
    "            temperature=0,\n",
    "            max_tokens=None,\n",
    "            timeout=None,\n",
    "            max_retries=2,\n",
    "            # api_key=\"...\",\n",
    "            # other params...\n",
    "        )\n",
    "    chain = build_chian_from_llms(model)\n",
    "    res = chain.invoke({\"text\": \"\"\"Alpha Insurance is an insurance company that provides its clients with various types of insurance policies. \n",
    "As soon as a customer addresses Alpha Insurance, a broker is assigned to follow the customerâ€™s file. The broker is registered in the system, so that when a customer calls, based on the contract, the help desk can immediately trace who is the customer's first account manager. After the broker is assigned to the customer, the latter indicates which type(s) of insurance policy they would like to sign for, so the broker could, depending on the case, either assess the customerâ€™s profile on the spot or send the customerâ€™s file for analysis to the head office. After the customerâ€™s profile has been assessed and the customer has been deemed trustworthy , a preliminary contract/offer on an insurance product is made to the customer either in person or by email. (Such offers can also be extended to already existing customers.) If the customer agrees to the offer, the contract is signed by both parties. After the signing of the contract, the client enjoys the coverage and is invoiced (monthly or yearly â€“ depending on the choice made in the contract) according to the price of the insurance product they bought.\n",
    "\n",
    "In case the insured event happens, a customer should send a claim for compensation. Then the company opens one or several claim cases (e.g. in case of an accident, often material damage & physical damage are handled separately). Once the case file is complete, it is sent for assessment by different estimators based on their area of expertise. According to the reports issued by the estimators, it is decided whether the claim case is approved. In case of approval the compensation decision is registered that stipulates which costs are eligible for (partial) refund.  For the supplied documents, the sum of compensation is calculated and the compensation is paid to the customerâ€™s account.  The estimatorsâ€™ reports must be stored in the database for at least one year after the payment of compensation for legal purposes. \n",
    "\n",
    "\"\"\"})\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e541373a-d3a2-407c-84f3-797f0f9a22e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def deepseek_cot2(model):\n",
    "    model_ = ChatDeepSeek(model=model)\n",
    "    chain = build_chian_from_llms(model_)\n",
    "    process_subfolders_with_chain(ROOT_FOLDER, chain, type=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "77eedad8-9f53-4e91-9166-5deff5dcca32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "```plantuml\n",
       "@startuml\n",
       "class InsuranceCompany{}\n",
       "class Client{}\n",
       "class Broker{}\n",
       "class InsurancePolicy{}\n",
       "class Contract{}\n",
       "class Offer{}\n",
       "class Coverage{}\n",
       "class Invoice{}\n",
       "class Claim{}\n",
       "class ClaimCase{}\n",
       "class Accident{}\n",
       "class MaterialDamage{}\n",
       "class PhysicalDamage{}\n",
       "class Estimator{}\n",
       "class Report{}\n",
       "class Decision{}\n",
       "class Refund{}\n",
       "class Document{}\n",
       "class Payment{}\n",
       "\n",
       "InsuranceCompany \"1..1\" -- \"0..*\" Client\n",
       "Client \"1..1\" -- \"0..*\" InsurancePolicy\n",
       "Broker \"1..1\" -- \"0..*\" Client\n",
       "Client \"1..1\" -- \"0..1\" Broker\n",
       "InsurancePolicy \"1..1\" -- \"1..1\" Contract\n",
       "Contract \"1..1\" -- \"0..1\" Offer\n",
       "InsurancePolicy \"1..1\" -- \"1..*\" Coverage\n",
       "InsurancePolicy \"1..1\" -- \"0..*\" Invoice\n",
       "Client \"1..1\" -- \"0..*\" Claim\n",
       "Claim \"1..1\" -- \"1..*\" ClaimCase\n",
       "ClaimCase \"1..1\" -- \"0..1\" Accident\n",
       "Accident \"1..1\" -- \"0..*\" MaterialDamage\n",
       "Accident \"1..1\" -- \"0..*\" PhysicalDamage\n",
       "ClaimCase \"1..1\" -- \"0..*\" Estimator\n",
       "Estimator \"1..1\" -- \"0..*\" Report\n",
       "ClaimCase \"1..1\" -- \"0..1\" Decision\n",
       "Decision \"1..1\" -- \"0..1\" Refund\n",
       "ClaimCase \"1..1\" -- \"0..*\" Document\n",
       "Refund \"1..1\" -- \"0..1\" Payment\n",
       "@enduml\n",
       "```"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 174 ms, sys: 22.1 ms, total: 196 ms\n",
      "Wall time: 1min 2s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "display_markdown(deepseek_make_example(MODEL_DEEPSEEK[0]), raw=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ddf12032-8bd6-46f0-a9e8-307437b37024",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COT2 with deepseek-chat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [28:35<00:00, 35.74s/it]\n"
     ]
    }
   ],
   "source": [
    "for model in MODEL_DEEPSEEK:\n",
    "    print(f\"COT2 with {model}\")\n",
    "    deepseek_cot2(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e30f2b7-0eb2-465a-9224-98a42a171fe0",
   "metadata": {},
   "source": [
    "## Ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "848047d5-35d6-4272-9ba4-a1e6a39346bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6ce832ba-b152-4775-87cd-c69565f67b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_OLLAMA = [] #[\"llama3.2:3b-text-fp16\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "df4335f3-03a9-45af-8d82-bba70439807a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ollama_cot2(model):\n",
    "    model_ = ChatOllama(\n",
    "        model=model,\n",
    "        temperature=0,\n",
    "    )\n",
    "    chain = build_chian_from_llms(model_)\n",
    "    process_subfolders_with_chain(ROOT_FOLDER, chain, type=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0477e649-cfda-4654-a52c-c58940935865",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ollama_make_example(model):\n",
    "    model = ChatOllama(\n",
    "        model=model,\n",
    "        temperature=0,\n",
    "    )\n",
    "    chain = build_chian_from_llms(model)\n",
    "    res = chain.invoke({\"text\": \"\"\"Alpha Insurance is an insurance company that provides its clients with various types of insurance policies. \n",
    "As soon as a customer addresses Alpha Insurance, a broker is assigned to follow the customerâ€™s file. The broker is registered in the system, so that when a customer calls, based on the contract, the help desk can immediately trace who is the customer's first account manager. After the broker is assigned to the customer, the latter indicates which type(s) of insurance policy they would like to sign for, so the broker could, depending on the case, either assess the customerâ€™s profile on the spot or send the customerâ€™s file for analysis to the head office. After the customerâ€™s profile has been assessed and the customer has been deemed trustworthy , a preliminary contract/offer on an insurance product is made to the customer either in person or by email. (Such offers can also be extended to already existing customers.) If the customer agrees to the offer, the contract is signed by both parties. After the signing of the contract, the client enjoys the coverage and is invoiced (monthly or yearly â€“ depending on the choice made in the contract) according to the price of the insurance product they bought.\n",
    "\n",
    "In case the insured event happens, a customer should send a claim for compensation. Then the company opens one or several claim cases (e.g. in case of an accident, often material damage & physical damage are handled separately). Once the case file is complete, it is sent for assessment by different estimators based on their area of expertise. According to the reports issued by the estimators, it is decided whether the claim case is approved. In case of approval the compensation decision is registered that stipulates which costs are eligible for (partial) refund.  For the supplied documents, the sum of compensation is calculated and the compensation is paid to the customerâ€™s account.  The estimatorsâ€™ reports must be stored in the database for at least one year after the payment of compensation for legal purposes. \n",
    "\n",
    "\"\"\"})\n",
    "    return res\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "33afa71e-b8c6-4c49-b11b-b89cfb704409",
   "metadata": {},
   "outputs": [],
   "source": [
    "#display_markdown(ollama_make_example(MODEL_OLLAMA[0]), raw=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "48b60c86-7d08-4790-b5ae-b875c102788e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in MODEL_OLLAMA:\n",
    "    print(f\"COT with {model}\")\n",
    "    ollama_cot2(model)\n",
    "    gc.collect()\n",
    "    torch.mps.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db448981-cf0a-42b5-b7ed-cb73bf0fbb56",
   "metadata": {},
   "source": [
    "## Huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "96994dbd-a971-4ae7-9ee9-5d0705d9a2ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marcocalamo/anaconda3/lib/python3.11/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: 'dlopen(/Users/marcocalamo/anaconda3/lib/python3.11/site-packages/torchvision/image.so, 0x0006): Symbol not found: __ZN3c1017RegisterOperatorsD1Ev\n",
      "  Referenced from: <9DBE5D5C-AC87-30CA-96DA-F5BC116EDA2B> /Users/marcocalamo/anaconda3/lib/python3.11/site-packages/torchvision/image.so\n",
      "  Expected in:     <A51C8C05-245A-3989-8D3C-9A6704422CA5> /Users/marcocalamo/anaconda3/lib/python3.11/site-packages/torch/lib/libtorch_cpu.dylib'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "from langchain_huggingface import HuggingFacePipeline, ChatHuggingFace, HuggingFaceEndpoint\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b07eead8-de14-4dc8-95bf-02c77101f9dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_HUGGINGFACE = [] #[\"google/gemma-2-2b-it\"] #[\"Qwen/Qwen2.5-3B-Instruct\", \"microsoft/Phi-3-mini-4k-instruct\", \"google/gemma-2-27b-it\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ccce77e7-20f7-45b0-817b-b04107541a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def huggingface_cot2(model):\n",
    "    model_id = model\n",
    "    \n",
    "    llm = HuggingFaceEndpoint(\n",
    "        repo_id=model_id,\n",
    "        task=\"text-generation\",\n",
    "        max_new_tokens=2048,\n",
    "        do_sample=False,\n",
    "        repetition_penalty=1.03,\n",
    "        temperature=0.01,\n",
    "    )\n",
    "\n",
    "    chat = ChatHuggingFace(llm=llm, verbose=True)\n",
    "    \n",
    "    chain = build_chian_from_llms(chat)\n",
    "    process_subfolders_with_chain(ROOT_FOLDER, chain, type=model_id.replace(\"/\",\"_\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a8cab307-e878-41a6-a13d-0f6904a4f30c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def huggingface_make_example(model):\n",
    "\n",
    "    model_id = model\n",
    "    \n",
    "    llm = HuggingFacePipeline.from_model_id(\n",
    "        model_id=model_id,\n",
    "        task=\"text-generation\",\n",
    "        pipeline_kwargs={\"temperature\": 0.1, \"max_new_tokens\": 1024}\n",
    "    )\n",
    "\n",
    "    chat = ChatHuggingFace(llm=llm, verbose=True)\n",
    "    \n",
    "    chain = build_chian_from_llms(chat)\n",
    "    res = chain.invoke({\"text\": \"\"\"Alpha Insurance is an insurance company that provides its clients with various types of insurance policies. \n",
    "        As soon as a customer addresses Alpha Insurance, a broker is assigned to follow the customerâ€™s file. The broker is registered in the system, so that when a customer calls, based on the contract, the help desk can immediately trace who is the customer's first account manager. After the broker is assigned to the customer, the latter indicates which type(s) of insurance policy they would like to sign for, so the broker could, depending on the case, either assess the customerâ€™s profile on the spot or send the customerâ€™s file for analysis to the head office. After the customerâ€™s profile has been assessed and the customer has been deemed trustworthy , a preliminary contract/offer on an insurance product is made to the customer either in person or by email. (Such offers can also be extended to already existing customers.) If the customer agrees to the offer, the contract is signed by both parties. After the signing of the contract, the client enjoys the coverage and is invoiced (monthly or yearly â€“ depending on the choice made in the contract) according to the price of the insurance product they bought.\n",
    "        \n",
    "        In case the insured event happens, a customer should send a claim for compensation. Then the company opens one or several claim cases (e.g. in case of an accident, often material damage & physical damage are handled separately). Once the case file is complete, it is sent for assessment by different estimators based on their area of expertise. According to the reports issued by the estimators, it is decided whether the claim case is approved. In case of approval the compensation decision is registered that stipulates which costs are eligible for (partial) refund.  For the supplied documents, the sum of compensation is calculated and the compensation is paid to the customerâ€™s account.  The estimatorsâ€™ reports must be stored in the database for at least one year after the payment of compensation for legal purposes. \n",
    "        \n",
    "        \"\"\"})\n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6cfe2884-9b34-4874-ae95-9985e4a09870",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#display_markdown(huggingface_make_example(MODEL_HUGGINGFACE[0]), raw=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ba9b628f-024e-450a-8d85-2db5b0c67c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in MODEL_HUGGINGFACE:\n",
    "    print(f\"COT2 with {model}\")\n",
    "    huggingface_cot2(model)\n",
    "    gc.collect()\n",
    "    torch.mps.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e76f5762-513f-4c2d-93f8-10598a2e7827",
   "metadata": {},
   "source": [
    "## Mlx-LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a61c5ea0-0f4a-4cc2-8220-0d38d8f91bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.llms import MLXPipeline\n",
    "from langchain_community.chat_models import ChatMLX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6c805336-ba69-459f-9fd9-3271aeec6aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_MLX = [\"mlx-community/phi-4-8bit\",\n",
    "             \"mlx-community/Falcon3-10B-Instruct-8bit\", \n",
    "             \"mlx-community/Qwen2.5-14B-Instruct-4bit\",\n",
    "             \"mlx-community/Mistral-7B-Instruct-v0.3-4bit\",\n",
    "             \"mlx-community/DeepSeek-R1-Distill-Qwen-7B-8bit\",\n",
    "             \"mlx-community/Llama-3.2-3B-Instruct\",\n",
    "             \"mlx-community/gemma-2-9b-8bit\",\n",
    "             #\"mlx-community/gemma-2-27b-it-4bit\",\n",
    "            # \"mlx-community/Mamba-Codestral-7B-v0.1-8bit\",\n",
    "            #\"mlx-community/CodeLlama-13b-Instruct-hf-4bit-MLX\"\n",
    "            ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "958151bc-0e7e-418a-9127-98d1e00e558b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlx_cot2(model):\n",
    "    llm = MLXPipeline.from_model_id(\n",
    "        model_id=model,\n",
    "        pipeline_kwargs={\"max_tokens\": 30_000, \"temp\": 0.1},\n",
    "    )\n",
    "    chat = ChatMLX(llm=llm)\n",
    "    chain = build_chian_from_llms(chat)\n",
    "    process_subfolders_with_chain(ROOT_FOLDER, chain, type=model.replace(\"/\",\"_\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "68a8ee38-7b7b-4a1f-8dec-02cb504b53b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlx_make_example(model):\n",
    "    llm = MLXPipeline.from_model_id(\n",
    "        model_id=model,\n",
    "        pipeline_kwargs={\"max_tokens\": 3000, \"temp\": 0.7},\n",
    "    )\n",
    "    chat = ChatMLX(llm=llm)\n",
    "    chain = build_chian_from_llms(chat)\n",
    "    res = chain.invoke({\"text\": \"\"\"Alpha Insurance is an insurance company that provides its clients with various types of insurance policies. \n",
    "As soon as a customer addresses Alpha Insurance, a broker is assigned to follow the customerâ€™s file. The broker is registered in the system, so that when a customer calls, based on the contract, the help desk can immediately trace who is the customer's first account manager. After the broker is assigned to the customer, the latter indicates which type(s) of insurance policy they would like to sign for, so the broker could, depending on the case, either assess the customerâ€™s profile on the spot or send the customerâ€™s file for analysis to the head office. After the customerâ€™s profile has been assessed and the customer has been deemed trustworthy , a preliminary contract/offer on an insurance product is made to the customer either in person or by email. (Such offers can also be extended to already existing customers.) If the customer agrees to the offer, the contract is signed by both parties. After the signing of the contract, the client enjoys the coverage and is invoiced (monthly or yearly â€“ depending on the choice made in the contract) according to the price of the insurance product they bought.\n",
    "\n",
    "In case the insured event happens, a customer should send a claim for compensation. Then the company opens one or several claim cases (e.g. in case of an accident, often material damage & physical damage are handled separately). Once the case file is complete, it is sent for assessment by different estimators based on their area of expertise. According to the reports issued by the estimators, it is decided whether the claim case is approved. In case of approval the compensation decision is registered that stipulates which costs are eligible for (partial) refund.  For the supplied documents, the sum of compensation is calculated and the compensation is paid to the customerâ€™s account.  The estimatorsâ€™ reports must be stored in the database for at least one year after the payment of compensation for legal purposes. \n",
    "\n",
    "\"\"\"})\n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "30a9e5a1-d9a8-447f-877e-645a04c5d2e4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6951ae490d37477599f0e2704a39dab2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 10 files:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "@startuml\n",
       "class AlphaInsurance{}\n",
       "class Client{}\n",
       "class Broker{}\n",
       "class Contract{}\n",
       "class InsurancePolicy{}\n",
       "class Profile{}\n",
       "class HeadOffice{}\n",
       "class Offer{}\n",
       "class InsuredEvent{}\n",
       "class Claim{}\n",
       "class Case{}\n",
       "class Estimator{}\n",
       "class Report{}\n",
       "class Compensation{}\n",
       "class Database{}\n",
       "\n",
       "Client \"0..*\" -- \"1..1\" Broker\n",
       "Client \"0..*\" -- \"0..1\" Profile\n",
       "Client \"1..1\" -- \"0..1\" Contract\n",
       "Broker \"0..*\" -- \"0..*\" Contract\n",
       "Contract \"0..*\" -- \"0..1\" InsurancePolicy\n",
       "Contract \"0..*\" -- \"0..*\" Offer\n",
       "Contract \"0..*\" -- \"0..*\" Claim\n",
       "Claim \"0..*\" -- \"1..1\" Case\n",
       "Case \"0..*\" -- \"0..*\" Estimator\n",
       "Case \"0..*\" -- \"0..1\" Compensation\n",
       "Estimator \"0..*\" -- \"0..*\" Report\n",
       "Report \"0..*\" -- \"0..1\" Database\n",
       "@enduml"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_markdown(mlx_make_example(MODEL_MLX[2]), raw=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ccea0873-879d-4fcb-a1a0-d97197370751",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION\"] = \"python\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bd6172f7-9306-4653-855b-ba6b03340bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc, torch\n",
    "gc.collect()\n",
    "torch.mps.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5d835f1b-7493-4a1b-8c51-26142777d17d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COT with mlx-community/Mistral-7B-Instruct-v0.3-4bit\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63a8502af39d44f4bbcd997ba304e00b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 7 files:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 44/44 [53:28<00:00, 72.93s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COT with mlx-community/DeepSeek-R1-Distill-Qwen-7B-8bit\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e10d8aae5fa4bb0bddd943c87f65a45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 7 files:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 44/44 [2:40:17<00:00, 218.58s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COT with mlx-community/Llama-3.2-3B-Instruct\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ccfe5ad93184f3eb1663499910f4d62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 7 files:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 44/44 [33:09<00:00, 45.22s/it]\n"
     ]
    }
   ],
   "source": [
    "for model in MODEL_MLX[3:]:\n",
    "    print(f\"COT2 with {model}\")\n",
    "    mlx_cot2(model)\n",
    "    import gc, torch\n",
    "    gc.collect()\n",
    "    torch.mps.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0067e756-9fdc-4a62-9aef-70ac6df19f12",
   "metadata": {},
   "source": [
    "### Clean Cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c3904bc0-b746-400e-b5f0-4988b10d459e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc, torch\n",
    "gc.collect()\n",
    "torch.mps.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "736c97d6-1430-42bc-88f2-58f47e331c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_relations(predicted, correct):\n",
    "    \"\"\"\n",
    "        compute precision, recall, f1\n",
    "\n",
    "        and score from 0 to 5 assigned this way:\n",
    "            - 1 point if relation exists\n",
    "            - up to 5 points for the cardinality\n",
    "    \"\"\"\n",
    "\n",
    "    total_score = 0\n",
    "    true_pos = 0\n",
    "    tp_fn = len(correct)\n",
    "    tp_fp = len(predicted)\n",
    "    \n",
    "    for rel in correct:\n",
    "        score = 0\n",
    "        for rel_ in predicted: \n",
    "            if set(rel.keys()) == set(rel_.keys()):\n",
    "                true_pos += 1\n",
    "                score += 1\n",
    "                for r in rel.keys():\n",
    "                    ## unify cardinality format\n",
    "                    if \"..\" not in rel[r]:\n",
    "                        rel[r] = '\"' + rel[r].replace('\"','') + \"..\"+ rel[r].replace('\"','') +'\"'\n",
    "\n",
    "                    if \"..\" not in rel_[r]:\n",
    "                        rel_[r] = '\"' + rel_[r].replace('\"','') + \"..\"+ rel_[r].replace('\"','') + '\"'\n",
    "        \n",
    "                    c_min = rel[r].split(\"..\")[0]\n",
    "                    c_min_ = rel_[r].split(\"..\")[0]\n",
    "\n",
    "                    if c_min == c_min_:\n",
    "                        score+=1\n",
    "\n",
    "                    c_max = rel[r].split(\"..\")[1]\n",
    "                    c_max_ = rel_[r].split(\"..\")[1]\n",
    "\n",
    "                    if c_max == c_max_:\n",
    "                        score+=1\n",
    "\n",
    "        total_score += score\n",
    "\n",
    "    if total_score > len(correct) * 5:\n",
    "        total_score = len(correct) * 5\n",
    "\n",
    "    if true_pos > 0 :\n",
    "        precision = true_pos / tp_fp \n",
    "        recall = true_pos / tp_fn \n",
    "        f1 = 2 * ((precision * recall) / (precision + recall))\n",
    "\n",
    "        if precision > 1 :\n",
    "            precision = 1\n",
    "        if recall > 1:\n",
    "            recall = 1\n",
    "        if f1 > 1 :\n",
    "            f1 = 1\n",
    "    else:\n",
    "        precision = 0\n",
    "        recall = 0\n",
    "        f1 = 0\n",
    "    \n",
    "    return {\n",
    "        \"total_score\":total_score,\n",
    "        \"precision\": round(precision,2),\n",
    "        \"recall\": round(recall,2),\n",
    "        \"f1\": round(f1,2),\n",
    "        \"len\":len(correct) * 5\n",
    "    }\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2f5aec6b-ca58-427a-be6f-2921d5f41417",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_class(predicted, correct):\n",
    "    \"\"\"\n",
    "    Computes precision, recall, and F1-score between the predicted and correct lists.\n",
    "\n",
    "    Args:\n",
    "        predicted (list): The list of predicted values.\n",
    "        correct (list): The list of correct (ground truth) values.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary with precision, recall, and F1-score.\n",
    "    \"\"\"\n",
    "\n",
    "    # precision: how many predicted that are in correct.\n",
    "    if type(predicted) != type(set()):\n",
    "        precision =  (len(set(predicted).intersection(set(correct)))) / len(set(predicted))\n",
    "    else:\n",
    "        precision =  (len((predicted).intersection((correct)))) / len((predicted))\n",
    "\n",
    "    \n",
    "    # recall : how many predicted are not in correct.\n",
    "    if type(predicted) != type(set()):\n",
    "        recall =  (len(set(predicted).intersection(set(correct)))) / len(set(correct)) \n",
    "    else:\n",
    "        recall = (len((predicted).intersection((correct)))) / len((correct)) \n",
    "\n",
    "    # f1: classic f1\n",
    "    f1 = 2 * ((precision * recall) / (precision + recall))\n",
    "\n",
    "    return {\n",
    "        \"precision\": round(precision,2),\n",
    "        \"recall\": round(recall,2),\n",
    "        \"f1\": round(f1,2)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "26dd9909-0ba3-44cd-93a8-ba1a2322291b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_parser():\n",
    "    with open(\"/Users/marcocalamo/Downloads/grammar.ebnf\", encoding=\"utf-8\") as grammar_file:\n",
    "        parser = Lark(grammar_file.read())\n",
    "        return parser\n",
    "\n",
    "\n",
    "import re \n",
    "\n",
    "def parse_text(parser, ref):\n",
    "    ref = ref.replace('`','')\n",
    "    ref = ref.replace('plantuml','')\n",
    "    ref = ref.replace('plaintext', '')\n",
    "\n",
    "    if not '@startuml' in ref:\n",
    "        ref = '@startuml\\n' + ref\n",
    "    if not '@enduml' in ref:\n",
    "        ref = ref+'\\n@enduml'\n",
    "    #ref = ref.replace('@startuml','')\n",
    "    #ref = ref.replace('@enduml','')\n",
    "\n",
    "    ref = re.sub(r\"<think>.*?</think>\", \"\", ref, flags=re.DOTALL)\n",
    "    \n",
    "    parsed_ref = parser.parse(ref)\n",
    "    return parsed_ref\n",
    "\n",
    "def get_from_parsed(parsed_text, to_get=\"class\"):\n",
    "    found = parsed_text.find_pred(lambda v: v.data.value == to_get)\n",
    "    \n",
    "    to_ret = []\n",
    "\n",
    "    for f in found:\n",
    "        if to_get == 'relationship':\n",
    "            one_rel = f.children[0].children            \n",
    "            first_rel = one_rel[0].children[0].value\n",
    "            assert one_rel[0].children[0].type == 'CNAME'\n",
    "\n",
    "            try:\n",
    "                first_card = one_rel[1].children[0].value\n",
    "                assert one_rel[1].children[0].type == 'ESCAPED_STRING'\n",
    "            except:\n",
    "                first_card = \"0..*\"\n",
    "\n",
    "            try:\n",
    "                second_card = one_rel[5].children[0].value\n",
    "                assert one_rel[5].children[0].type == 'ESCAPED_STRING'\n",
    "            except:\n",
    "                second_card = \"0..*\"\n",
    "\n",
    "            second_rel = one_rel[-2].children[0].value\n",
    "            assert one_rel[-2].children[0].type == 'CNAME'\n",
    "            \n",
    "            rel_tuple = {\n",
    "                first_rel:first_card,\n",
    "                second_rel:second_card\n",
    "            }\n",
    "            \n",
    "            to_ret.append(rel_tuple)\n",
    "        elif to_get == 'class':\n",
    "            to_ret.append(f.children[0].children[0].value)\n",
    "    \n",
    "    return to_ret\n",
    "    \n",
    "def parse_path(path_to_uml, parser):\n",
    "    \n",
    "    if os.path.isfile(path_to_uml):\n",
    "        with open(path_to_uml) as plant_ref:\n",
    "            \n",
    "            ref = plant_ref.read()\n",
    "            parsed_ref = parse_text(parser, ref)\n",
    "            found_class = get_from_parsed(parsed_ref, to_get=\"class\")\n",
    "            found_rel = get_from_parsed(parsed_ref, to_get=\"relationship\")\n",
    "\n",
    "            return found_class, found_rel\n",
    "    else:\n",
    "        raise FileNotFoundError\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "014ca02c-77a5-4e91-bec1-3fc63aef5900",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'lark'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlark\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Lark\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mos\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'lark'"
     ]
    }
   ],
   "source": [
    "from lark import Lark\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b950a5-85f0-46ba-9377-cb44b175bced",
   "metadata": {},
   "outputs": [],
   "source": [
    "#parse_path(\"/Users/marcocalamo/KUL/Dataset/AuthorsAndBooks/uml.txt\", init_parser())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e56e35e6-4d84-494b-b242-76b9c101f4eb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#parse_path(\"/Users/marcocalamo/KUL/Dataset/Alpha_Insurance_Basic/result_cot_gpt-3.5-turbo.txt\", init_parser())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3abbf13d-a8b7-4056-b7f3-f918ed522155",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(path_uml, path_to_check, parser):\n",
    "\n",
    "    # gold class and rel\n",
    "    class_uml, rel_uml = parse_path(path_uml, parser)\n",
    "\n",
    "    # candidate class and rel\n",
    "    class_check, rel_check = parse_path(path_to_check, parser)\n",
    "\n",
    "    # check class\n",
    "    res_cl = check_class(class_check, class_uml)\n",
    "\n",
    "    # check rel\n",
    "    res_re = check_relations(rel_check, rel_uml)\n",
    "\n",
    "    return res_cl, res_re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24eadd67-a4b2-4f3c-84f3-62f2129a9471",
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluate(\"/Users/marcocalamo/KUL/Dataset/AuthorsAndBooks/uml.txt\", \"/Users/marcocalamo/KUL/Dataset/AuthorsAndBooks/result_cot_mlx-community_phi-4-8bit.txt\",init_parser())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b66c99e3-45c4-4319-a353-48798542707e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "\n",
    "def process_folders(root_folder):\n",
    "    csv_file = os.path.join(root_folder, \"evaluation_results.csv\")\n",
    "    header_written = False\n",
    "    \n",
    "    with open(csv_file, mode='w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        \n",
    "        for sub_folder in os.listdir(root_folder):\n",
    "            sub_folder_path = os.path.join(root_folder, sub_folder)\n",
    "            if not os.path.isdir(sub_folder_path):\n",
    "                continue\n",
    "\n",
    "            uml_file = os.path.join(sub_folder_path, \"uml.txt\")\n",
    "            if not os.path.exists(uml_file):\n",
    "                continue\n",
    "            \n",
    "            for filename in os.listdir(sub_folder_path):\n",
    "                if filename.startswith(\"result_\") and filename.endswith(\".txt\"):\n",
    "                    result_file = os.path.join(sub_folder_path, filename)\n",
    "                    model_name = \"-\".join(filename.replace(\".txt\", \"\").split(\"_\")[1:])\n",
    "                    parser = init_parser()\n",
    "                    try:\n",
    "                        results = evaluate(uml_file, result_file, parser)\n",
    "                        if not header_written:\n",
    "                            writer.writerow([\"sub_folder_name\", \"model_name\", \n",
    "                                             \"precision_class\", \"recall_class\", \"f1_class\",\n",
    "                                             \"precision_rel\", \"recall_rel\", \"f1_rel\", \"score_rel\", \"max_score\"])\n",
    "                            header_written = True\n",
    "                        writer.writerow([sub_folder, model_name, results[0][\"precision\"], results[0][\"recall\"], results[0][\"f1\"],\n",
    "                                        results[1][\"precision\"], results[1][\"recall\"], results[1][\"f1\"],\n",
    "                                        results[1][\"total_score\"], results[1][\"len\"]])\n",
    "                    except Exception as e:\n",
    "                        print(e,sub_folder, model_name)\n",
    "                        with open(\"trace.txt\", mode=\"a\") as t:\n",
    "                            t.write(str(e) + str(sub_folder)+str (model_name))\n",
    "                        #raise Exception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "396b5007-a0ab-4327-8064-226c1aac489d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#process_folders(ROOT_FOLDER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b55db72-6c9b-4d12-af98-33f907c03786",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_counts(ax, df):\n",
    "    for c in ax.containers:\n",
    "        # Extract heights and match with correct counts\n",
    "        labels = [f'N={int(row[\"count\"])}' for (idx, row) in (df.iterrows()) ]\n",
    "        # Add the count labels to the bars\n",
    "        try:\n",
    "            ax.bar_label(c, labels=labels, label_type='edge', fontsize=10, padding=3)\n",
    "        except:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d72ec56-69e3-4372-b8cd-d0701c3aa7da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a list of possible prefixes\n",
    "prefixes = ['cot', 'cot2']\n",
    "\n",
    "# Function to extract base model name and result type based on prefixes\n",
    "def extract_base_and_type(model_name):\n",
    "    for prefix in prefixes:\n",
    "        if model_name.startswith(f'{prefix}-'):\n",
    "            return model_name.replace(f'{prefix}-', ''), prefix\n",
    "    return model_name, 'standard'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9450d15-b93e-4b51-b264-6414382db18f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_data_class(csv):\n",
    "    # Load the CSV file\n",
    "    df = pd.read_csv(csv)\n",
    "    \n",
    "    # Extract the base model name and determine result type\n",
    "    df[['base_model_name', 'result_type']] = df['model_name'].apply(\n",
    "        lambda x: pd.Series(extract_base_and_type(x))\n",
    "    )\n",
    "\n",
    "    # Compute averages and instance counts\n",
    "    avg_metrics = df.groupby(['base_model_name', 'model_name', 'result_type']).agg(\n",
    "        f1_class_avg=('f1_class', 'mean'),\n",
    "        count=('model_name', 'count')\n",
    "    ).reset_index()\n",
    "\n",
    "    \n",
    "    # Set seaborn style\n",
    "    sns.set_theme(style='whitegrid')\n",
    "    \n",
    "    # Define a color palette for base model names\n",
    "    unique_base_models = avg_metrics['base_model_name'].unique()\n",
    "    base_palette = sns.color_palette(\"tab10\", len(unique_base_models))\n",
    "    color_map = {model: base_palette[i] for i, model in enumerate(unique_base_models)}\n",
    "    \n",
    "    # Generate colors for the bars, ensuring each base model has the same color for both result types\n",
    "    avg_metrics['color'] = avg_metrics['base_model_name'].map(color_map)\n",
    "    \n",
    "    # Plot average f1_class per model with result types\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    ax = sns.barplot(\n",
    "        x='base_model_name', y='f1_class_avg', hue='result_type', \n",
    "        data=avg_metrics, palette='husl' #palette=[color_map[m] for m in avg_metrics['base_model_name']]\n",
    "    )\n",
    "\n",
    "    # Annotate counts on bars correctly\n",
    "    for count, score in zip(avg_metrics['count'], avg_metrics['f1_class_avg']):        \n",
    "        for p in ax.patches:\n",
    "            if p.get_height() == score:\n",
    "                ax.annotate(f'N={count}', \n",
    "                            (p.get_x() + p.get_width() / 2., p.get_height()), \n",
    "                            ha='center', va='bottom', fontsize=10)\n",
    "    \n",
    "    \n",
    "    plt.title('Average F1 Class per Model')\n",
    "    plt.xlabel('Model Name')\n",
    "    plt.ylabel('Average F1 Class')\n",
    "    plt.xticks(rotation=30, ha='right')\n",
    "    plt.legend(title='Result Type')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_data_rel(csv):\n",
    "    df = pd.read_csv(csv)\n",
    "    \n",
    "    # Extract the base model name and determine result type\n",
    "    df[['base_model_name', 'result_type']] = df['model_name'].apply(\n",
    "        lambda x: pd.Series(extract_base_and_type(x))\n",
    "    )\n",
    "\n",
    "    # Compute averages and instance counts\n",
    "    avg_metrics = df.groupby(['base_model_name', 'model_name', 'result_type']).agg(\n",
    "        f1_rel_avg=('f1_rel', 'mean'),\n",
    "        count=('model_name', 'count')\n",
    "    ).reset_index()\n",
    "\n",
    "    \n",
    "    # Set seaborn style\n",
    "    sns.set_theme(style='whitegrid')\n",
    "    \n",
    "    # Define a color palette for base model names\n",
    "    unique_base_models = avg_metrics['base_model_name'].unique()\n",
    "    base_palette = sns.color_palette(\"tab10\", len(unique_base_models))\n",
    "    color_map = {model: base_palette[i] for i, model in enumerate(unique_base_models)}\n",
    "    \n",
    "    # Generate colors for the bars, ensuring each base model has the same color for both result types\n",
    "    avg_metrics['color'] = avg_metrics['base_model_name'].map(color_map)\n",
    "    \n",
    "    # Plot average f1_class per model with result types\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    ax = sns.barplot(\n",
    "        x='base_model_name', y='f1_rel_avg', hue='result_type', \n",
    "        data=avg_metrics, palette='husl' #palette=[color_map[m] for m in avg_metrics['base_model_name']]\n",
    "    )\n",
    "\n",
    "    # Annotate counts on bars correctly\n",
    "    for count, score in zip(avg_metrics['count'], avg_metrics['f1_rel_avg']):        \n",
    "        for p in ax.patches:\n",
    "            if p.get_height() == score:\n",
    "                ax.annotate(f'N={count}', \n",
    "                            (p.get_x() + p.get_width() / 2., p.get_height()), \n",
    "                            ha='center', va='bottom', fontsize=10)\n",
    "    \n",
    "        \n",
    "    plt.title('Average F1 Association per Model')\n",
    "    plt.xlabel('Model Name')\n",
    "    plt.ylabel('Average F1 Assoc')\n",
    "    plt.xticks(rotation=30, ha='right')\n",
    "    plt.legend(title='Result Type')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_data_score(csv):\n",
    "    # Load the CSV file\n",
    "    df = pd.read_csv(csv)\n",
    "    \n",
    "    # Extract the base model name and determine result type\n",
    "    df[['base_model_name', 'result_type']] = df['model_name'].apply(\n",
    "        lambda x: pd.Series(extract_base_and_type(x))\n",
    "    )\n",
    "\n",
    "    # Compute averages and instance counts\n",
    "    avg_metrics = df.groupby(['base_model_name', 'model_name', 'result_type']).agg(\n",
    "        score_avg=('score_rel', 'mean'),\n",
    "        count=('model_name', 'count')\n",
    "    ).reset_index()\n",
    "\n",
    "    \n",
    "    # Set seaborn style\n",
    "    sns.set_theme(style='whitegrid')\n",
    "    \n",
    "    # Define a color palette for base model names\n",
    "    unique_base_models = avg_metrics['base_model_name'].unique()\n",
    "    base_palette = sns.color_palette(\"tab10\", len(unique_base_models))\n",
    "    color_map = {model: base_palette[i] for i, model in enumerate(unique_base_models)}\n",
    "    \n",
    "    # Generate colors for the bars, ensuring each base model has the same color for both result types\n",
    "    avg_metrics['color'] = avg_metrics['base_model_name'].map(color_map)\n",
    "    \n",
    "    # Plot average f1_class per model with result types\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    ax = sns.barplot(\n",
    "        x='base_model_name', y='score_avg', hue='result_type', \n",
    "        data=avg_metrics, palette='husl' #palette=[color_map[m] for m in avg_metrics['base_model_name']]\n",
    "    )\n",
    "\n",
    "    # Annotate counts on bars correctly\n",
    "    for count, score in zip(avg_metrics['count'], avg_metrics['score_avg']):        \n",
    "        for p in ax.patches:\n",
    "            if p.get_height() == score:\n",
    "                ax.annotate(f'N={count}', \n",
    "                            (p.get_x() + p.get_width() / 2., p.get_height()), \n",
    "                            ha='center', va='bottom', fontsize=10)\n",
    "    \n",
    "    plt.title('Average Score per Model')\n",
    "    plt.xlabel('Model Name')\n",
    "    plt.ylabel('Average Score')\n",
    "    plt.xticks(rotation=30, ha='right')\n",
    "    plt.legend(title='Result Type')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "227491a7-f6a9-4827-acf5-759ce3508a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_data_class_pc(csv):\n",
    "    # Load the CSV file\n",
    "    df = pd.read_csv(csv)\n",
    "    \n",
    "    # Extract the base model name and determine result type\n",
    "    df[['base_model_name', 'result_type']] = df['model_name'].apply(\n",
    "        lambda x: pd.Series(extract_base_and_type(x))\n",
    "    )\n",
    "\n",
    "    # Compute averages and instance counts\n",
    "    avg_metrics = df.groupby(['sub_folder_name', 'base_model_name', 'model_name', 'result_type']).agg(\n",
    "        f1_class_avg=('f1_class', 'mean'),\n",
    "        count=('model_name', 'count')\n",
    "    ).reset_index()\n",
    "\n",
    "    \n",
    "    # Set seaborn style\n",
    "    sns.set_theme(style='whitegrid')\n",
    "    \n",
    "    # Define a color palette for base model names\n",
    "    unique_base_models = avg_metrics['base_model_name'].unique()\n",
    "    base_palette = sns.color_palette(\"tab10\", len(unique_base_models))\n",
    "    color_map = {model: base_palette[i] for i, model in enumerate(unique_base_models)}\n",
    "    \n",
    "    # Generate colors for the bars, ensuring each base model has the same color for both result types\n",
    "    avg_metrics['color'] = avg_metrics['base_model_name'].map(color_map)\n",
    "    \n",
    "    # Plot average f1_class per model with result types\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    ax = sns.barplot(\n",
    "        x='sub_folder_name', y='f1_class_avg', hue='result_type', \n",
    "        data=avg_metrics, palette='husl' #palette=[color_map[m] for m in avg_metrics['base_model_name']]\n",
    "    )\n",
    "\n",
    "    \n",
    "    \n",
    "    plt.title('Average F1 Class per Case')\n",
    "    plt.xlabel('Model Name')\n",
    "    plt.ylabel('Average F1 Class')\n",
    "    plt.xticks(rotation=30, ha='right')\n",
    "    plt.legend(title='Result Type')\n",
    "    plt.show()\n",
    "\n",
    "def plot_data_rel_pc(csv):\n",
    "    df = pd.read_csv(csv)\n",
    "    \n",
    "    # Extract the base model name and determine result type\n",
    "    df[['base_model_name', 'result_type']] = df['model_name'].apply(\n",
    "        lambda x: pd.Series(extract_base_and_type(x))\n",
    "    )\n",
    "\n",
    "    # Compute averages and instance counts\n",
    "    avg_metrics = df.groupby(['sub_folder_name', 'base_model_name', 'model_name', 'result_type']).agg(\n",
    "        f1_rel_avg=('f1_rel', 'mean'),\n",
    "        count=('model_name', 'count')\n",
    "    ).reset_index()\n",
    "\n",
    "    \n",
    "    # Set seaborn style\n",
    "    sns.set_theme(style='whitegrid')\n",
    "    \n",
    "    # Define a color palette for base model names\n",
    "    unique_base_models = avg_metrics['base_model_name'].unique()\n",
    "    base_palette = sns.color_palette(\"tab10\", len(unique_base_models))\n",
    "    color_map = {model: base_palette[i] for i, model in enumerate(unique_base_models)}\n",
    "    \n",
    "    # Generate colors for the bars, ensuring each base model has the same color for both result types\n",
    "    avg_metrics['color'] = avg_metrics['base_model_name'].map(color_map)\n",
    "    \n",
    "    # Plot average f1_class per model with result types\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    ax = sns.barplot(\n",
    "        x='sub_folder_name', y='f1_rel_avg', hue='result_type', \n",
    "        data=avg_metrics, palette='husl' #palette=[color_map[m] for m in avg_metrics['base_model_name']]\n",
    "    )\n",
    "\n",
    "        \n",
    "    plt.title('Average F1 Association per Case')\n",
    "    plt.xlabel('Model Name')\n",
    "    plt.ylabel('Average F1 Assoc')\n",
    "    plt.xticks(rotation=30, ha='right')\n",
    "    plt.legend(title='Result Type')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b8d9c9b-3d69-430d-821a-d8ec117baabe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_data_p_class(csv):\n",
    "    # Load the CSV file\n",
    "    df = pd.read_csv(csv)\n",
    "    \n",
    "    # Extract the base model name and determine result type\n",
    "    df[['base_model_name', 'result_type']] = df['model_name'].apply(\n",
    "        lambda x: pd.Series(extract_base_and_type(x))\n",
    "    )\n",
    "\n",
    "    # Compute averages and instance counts\n",
    "    avg_metrics = df.groupby(['base_model_name', 'model_name', 'result_type']).agg(\n",
    "        f1_class_avg=('precision_class', 'mean'),\n",
    "        count=('model_name', 'count')\n",
    "    ).reset_index()\n",
    "\n",
    "    \n",
    "    # Set seaborn style\n",
    "    sns.set_theme(style='whitegrid')\n",
    "    \n",
    "    # Define a color palette for base model names\n",
    "    unique_base_models = avg_metrics['base_model_name'].unique()\n",
    "    base_palette = sns.color_palette(\"tab10\", len(unique_base_models))\n",
    "    color_map = {model: base_palette[i] for i, model in enumerate(unique_base_models)}\n",
    "    \n",
    "    # Generate colors for the bars, ensuring each base model has the same color for both result types\n",
    "    avg_metrics['color'] = avg_metrics['base_model_name'].map(color_map)\n",
    "    \n",
    "    # Plot average f1_class per model with result types\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    ax = sns.barplot(\n",
    "        x='base_model_name', y='f1_class_avg', hue='result_type', \n",
    "        data=avg_metrics, palette='rocket' #palette=[color_map[m] for m in avg_metrics['base_model_name']]\n",
    "    )\n",
    "\n",
    "    # Annotate counts on bars correctly\n",
    "    for count, score in zip(avg_metrics['count'], avg_metrics['f1_class_avg']):        \n",
    "        for p in ax.patches:\n",
    "            if p.get_height() == score:\n",
    "                ax.annotate(f'N={count}', \n",
    "                            (p.get_x() + p.get_width() / 2., p.get_height()), \n",
    "                            ha='center', va='bottom', fontsize=10)\n",
    "    \n",
    "    \n",
    "    plt.title('Average Precision Class per Model')\n",
    "    plt.xlabel('Model Name')\n",
    "    plt.ylabel('Average Precision Class')\n",
    "    plt.xticks(rotation=30, ha='right')\n",
    "    plt.legend(title='Result Type')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_data_rel(csv):\n",
    "    df = pd.read_csv(csv)\n",
    "    \n",
    "    # Extract the base model name and determine result type\n",
    "    df[['base_model_name', 'result_type']] = df['model_name'].apply(\n",
    "        lambda x: pd.Series(extract_base_and_type(x))\n",
    "    )\n",
    "\n",
    "    # Compute averages and instance counts\n",
    "    avg_metrics = df.groupby(['base_model_name', 'model_name', 'result_type']).agg(\n",
    "        f1_rel_avg=('f1_rel', 'mean'),\n",
    "        count=('model_name', 'count')\n",
    "    ).reset_index()\n",
    "\n",
    "    \n",
    "    # Set seaborn style\n",
    "    sns.set_theme(style='whitegrid')\n",
    "    \n",
    "    # Define a color palette for base model names\n",
    "    unique_base_models = avg_metrics['base_model_name'].unique()\n",
    "    base_palette = sns.color_palette(\"tab10\", len(unique_base_models))\n",
    "    color_map = {model: base_palette[i] for i, model in enumerate(unique_base_models)}\n",
    "    \n",
    "    # Generate colors for the bars, ensuring each base model has the same color for both result types\n",
    "    avg_metrics['color'] = avg_metrics['base_model_name'].map(color_map)\n",
    "    \n",
    "    # Plot average f1_class per model with result types\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    ax = sns.barplot(\n",
    "        x='base_model_name', y='f1_rel_avg', hue='result_type', \n",
    "        data=avg_metrics, palette='husl' #palette=[color_map[m] for m in avg_metrics['base_model_name']]\n",
    "    )\n",
    "\n",
    "    # Annotate counts on bars correctly\n",
    "    for count, score in zip(avg_metrics['count'], avg_metrics['f1_rel_avg']):        \n",
    "        for p in ax.patches:\n",
    "            if p.get_height() == score:\n",
    "                ax.annotate(f'N={count}', \n",
    "                            (p.get_x() + p.get_width() / 2., p.get_height()), \n",
    "                            ha='center', va='bottom', fontsize=10)\n",
    "    \n",
    "        \n",
    "    plt.title('Average F1 Association per Model')\n",
    "    plt.xlabel('Model Name')\n",
    "    plt.ylabel('Average F1 Assoc')\n",
    "    plt.xticks(rotation=30, ha='right')\n",
    "    plt.legend(title='Result Type')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_data_score(csv):\n",
    "    # Load the CSV file\n",
    "    df = pd.read_csv(csv)\n",
    "    \n",
    "    # Extract the base model name and determine result type\n",
    "    df[['base_model_name', 'result_type']] = df['model_name'].apply(\n",
    "        lambda x: pd.Series(extract_base_and_type(x))\n",
    "    )\n",
    "\n",
    "    # Compute averages and instance counts\n",
    "    avg_metrics = df.groupby(['base_model_name', 'model_name', 'result_type']).agg(\n",
    "        score_avg=('score_rel', 'mean'),\n",
    "        count=('model_name', 'count')\n",
    "    ).reset_index()\n",
    "\n",
    "    \n",
    "    # Set seaborn style\n",
    "    sns.set_theme(style='whitegrid')\n",
    "    \n",
    "    # Define a color palette for base model names\n",
    "    unique_base_models = avg_metrics['base_model_name'].unique()\n",
    "    base_palette = sns.color_palette(\"tab10\", len(unique_base_models))\n",
    "    color_map = {model: base_palette[i] for i, model in enumerate(unique_base_models)}\n",
    "    \n",
    "    # Generate colors for the bars, ensuring each base model has the same color for both result types\n",
    "    avg_metrics['color'] = avg_metrics['base_model_name'].map(color_map)\n",
    "    \n",
    "    # Plot average f1_class per model with result types\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    ax = sns.barplot(\n",
    "        x='base_model_name', y='score_avg', hue='result_type', \n",
    "        data=avg_metrics, palette='husl' #palette=[color_map[m] for m in avg_metrics['base_model_name']]\n",
    "    )\n",
    "\n",
    "    # Annotate counts on bars correctly\n",
    "    for count, score in zip(avg_metrics['count'], avg_metrics['score_avg']):        \n",
    "        for p in ax.patches:\n",
    "            if p.get_height() == score:\n",
    "                ax.annotate(f'N={count}', \n",
    "                            (p.get_x() + p.get_width() / 2., p.get_height()), \n",
    "                            ha='center', va='bottom', fontsize=10)\n",
    "    \n",
    "    plt.title('Average Score per Model')\n",
    "    plt.xlabel('Model Name')\n",
    "    plt.ylabel('Average Score')\n",
    "    plt.xticks(rotation=30, ha='right')\n",
    "    plt.legend(title='Result Type')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a183a6e-a19a-438d-a271-b7a38b0bfceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data_class(\"/Users/marcocalamo/KUL/Dataset/evaluation_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63725529-f715-4356-b2c4-39c1b7982871",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data_p_class(\"/Users/marcocalamo/KUL/Dataset/evaluation_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe51197-b8dd-4ea5-bab3-1a8c7e9359cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data_class_pc(\"/Users/marcocalamo/KUL/Dataset/evaluation_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df36fc7e-6e81-468d-bb7b-5b9041725fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data_rel(\"/Users/marcocalamo/KUL/Dataset/evaluation_results.csv\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a727a5f9-dad8-4be9-be58-411d3563910f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data_rel_pc(\"/Users/marcocalamo/KUL/Dataset/evaluation_results.csv\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d15087-c66d-47da-b39b-e4bc7517155b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data_score(\"/Users/marcocalamo/KUL/Dataset/evaluation_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28833da5-8f4b-41dd-b501-e3ae5d46587e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# avg per case\n",
    "# precision - recall"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
