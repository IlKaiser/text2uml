{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1354cc70-f0e5-4ceb-8abb-e8290f9e4a05",
   "metadata": {},
   "source": [
    "# Template Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48051682-039d-4dea-80fa-416f0e56d4ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_FOLDER = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08b31a1d-21e0-4367-b55b-bc9b97164bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, PromptTemplate\n",
    "prompt_template = PromptTemplate.from_template(\n",
    "\"\"\"\n",
    "You will be asked by the user to create a plant UMl model from specification text. Do so in the most\n",
    "clear way possible, avoid class properties and assign molteplicity. \n",
    "\n",
    "Do not include attributes for classes. For example the class Book would be:\n",
    "\n",
    "class Book{{}}\n",
    "\n",
    "Use only bi-directional arc for relations and no description. For example a relation between\n",
    "the class Book and the class Page, if the Book can have from one to many pages and the \n",
    "pages could have exactly one book, would be:\n",
    "\n",
    "Book \"1..1\" -- \"1..*\" Page\n",
    "\n",
    "Adapt the cardinality to each case. If the cardinality would be \"0..*\", the default one, omit it.\n",
    "\n",
    "The plantuml has to be the class diagram. In generating the diagram perform this steps in order\n",
    "\n",
    "1. Extract class from text\n",
    "2. Extract relations form text\n",
    "3. Assign the relation to the corresponding class\n",
    "4. Add cardinality to the relations\n",
    "\n",
    "Put everything in this order: first all classes and then all relations. In our example would be:\n",
    "\n",
    "@startuml\n",
    "\n",
    "class Book{{}}\n",
    "class Page{{}}\n",
    "\n",
    "Book \"1..1\" -- \"1..*\" Page\n",
    "\n",
    "@enduml\n",
    "\n",
    "Output plantuml without futher text or explaination.\n",
    "\n",
    "##############\n",
    "\n",
    "Here is an example of how should be done. \n",
    "\n",
    "The specificartion example text is:\n",
    "\n",
    "Alpha Insurance is an insurance company that provides its clients with various types of insurance policies. \n",
    "As soon as a customer addresses Alpha Insurance, a broker is assigned to follow the customer’s file. \n",
    "The broker is registered in the system, so that when a customer calls, based on the contract, \n",
    "the help desk can immediately trace who is the customer's first account manager.\n",
    "After the broker is assigned to the customer, the latter indicates which type(s) of insurance policy they would like to sign for,\n",
    "so the broker could, depending on the case, either assess the customer’s profile on the spot or send the customer’s file\n",
    "for analysis to the head office. After the customer’s profile has been assessed and the customer has been deemed trustworthy,\n",
    "a preliminary contract/offer on an insurance product is made to the customer either in person or by email.\n",
    "(Such offers can also be extended to already existing customers.) \n",
    "If the customer agrees to the offer, the contract is signed by both parties.\n",
    "After the signing of the contract, the client enjoys the coverage and is invoiced\n",
    "(monthly or yearly – depending on the choice made in the contract) according to the price of the insurance product they bought.\n",
    "\n",
    "In case the insured event happens, a customer should send a claim for compensation.\n",
    "Then the company opens one or several claim cases (e.g. in case of an accident,\n",
    "often material damage & physical damage are handled separately). Once the case file is complete, \n",
    "it is sent for assessment by different estimators based on their area of expertise.\n",
    "According to the reports issued by the estimators, it is decided whether the claim case is approved. \n",
    "In case of approval the compensation decision is registered that stipulates which costs are eligible for (partial) refund.\n",
    "For the supplied documents, the sum of compensation is calculated and the compensation is paid to the customer’s account. \n",
    "\n",
    "The estimators’ reports must be stored in the database for at least one year after the payment of compensation for legal purposes. \n",
    "\n",
    "The corresponding uml is:\n",
    "\n",
    "@startuml\n",
    "\n",
    "class Customer {{}}\n",
    "class InsurancePolicy {{}}\n",
    "class Contract {{}}\n",
    "class Invoice {{}}\n",
    "class BrokerCustomerAssignment {{}}\n",
    "class Broker {{}}\n",
    "class ClaimCase {{}}\n",
    "class Report {{}}\n",
    "class Estimator {{}}\n",
    "class CompensationPayment {{}}\n",
    "\n",
    "Contract \"0..*\" -- \"1\" Customer\n",
    "Contract \"1\" -- \"0..*\" Invoice\n",
    "Contract \"0..*\" -- \"1\" Airline\n",
    "Contract \"1\" -- \"0..*\" InsurancePolicy\n",
    "Contract \"1\" -- \"0..*\" ClaimCase\n",
    "\n",
    "ClaimCase \"1\" -- \"0..*\" CompensationPayment\n",
    "ClaimCase \"1\" -- \"0..*\" Report\n",
    "Report \"0..*\" -- \"1\" Estimator\n",
    "BrokerCustomerAssignment \"0..1\" -- \"1\" Customer\n",
    "Broker \"1\" -- \"0..*\" BrokerCustomerAssignment\n",
    "\n",
    "@enduml\n",
    "\n",
    "##############\n",
    "\n",
    "The specification text is:\n",
    "\n",
    "{text}\n",
    "\n",
    "##############\n",
    "\n",
    "Based on the example, the uml output is:\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e52bfe56-9d50-4bd6-baae-0aeee67212fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import threading\n",
    "from time import sleep\n",
    "try:\n",
    "    import thread\n",
    "except ImportError:\n",
    "    import _thread as thread\n",
    "\n",
    "def quit_function(fn_name):\n",
    "    # print to stderr, unbuffered in Python 2.\n",
    "    print('{0} took too long'.format(fn_name), file=sys.stderr)\n",
    "    sys.stderr.flush() # Python 3 stderr is likely buffered.\n",
    "    thread.interrupt_main() # raises KeyboardInterrupt\n",
    "    \n",
    "def exit_after(s):\n",
    "    '''\n",
    "    use as decorator to exit process if \n",
    "    function takes longer than s seconds\n",
    "    '''\n",
    "    def outer(fn):\n",
    "        def inner(*args, **kwargs):\n",
    "            timer = threading.Timer(s, quit_function, args=[fn.__name__])\n",
    "            timer.start()\n",
    "            try:\n",
    "                result = fn(*args, **kwargs)\n",
    "            finally:\n",
    "                timer.cancel()\n",
    "            return result\n",
    "        return inner\n",
    "    return outer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "57cfbcd0-2bc0-4ba5-80b8-f14702706f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "from docx import Document\n",
    "\n",
    "from langchain_core.tracers.context import tracing_v2_enabled\n",
    "\n",
    "@exit_after(360)\n",
    "def run_chain(chain, text):\n",
    "    return chain.invoke({\"text\": text})\n",
    "\n",
    "def process_subfolders_with_chain(root_folder_path, chain, type=''):\n",
    "    \"\"\"\n",
    "    Explores subfolders of the root folder (depth 1), processes each subfolder's `text.txt`\n",
    "    with the provided LangChain chain, and saves the result in a new file in the same folder.\n",
    "\n",
    "    Args:\n",
    "        root_folder_path (str): Path to the root folder.\n",
    "        chain: A LangChain chain instance to process text inputs.\n",
    "    \"\"\"\n",
    "    for subfolder_name in tqdm(os.listdir(root_folder_path)):\n",
    "        subfolder_path = os.path.join(root_folder_path, subfolder_name)\n",
    "        \n",
    "        # Ensure the current item is a subfolder\n",
    "        if os.path.isdir(subfolder_path):\n",
    "            text_file_path = os.path.join(subfolder_path, \"text.txt\")\n",
    "            \n",
    "            # Check if `text.txt` exists in the subfolder\n",
    "            if not os.path.isfile(text_file_path):\n",
    "                # If `text.txt` is missing, check for any .docx file in the subfolder\n",
    "                docx_files = [f for f in os.listdir(subfolder_path) if f.endswith(\".docx\")]\n",
    "                if docx_files:\n",
    "                    docx_file_path = os.path.join(subfolder_path, docx_files[0])\n",
    "                    # Extract content from the .docx file\n",
    "                    doc = Document(docx_file_path)\n",
    "                    text_content = \"\\n\".join([paragraph.text for paragraph in doc.paragraphs])\n",
    "\n",
    "                    # Save the extracted content to `text.txt`\n",
    "                    with open(text_file_path, \"w\", encoding=\"utf-8\") as text_file:\n",
    "                        text_file.write(text_content)\n",
    "\n",
    "            # Recheck if `text.txt` now exists\n",
    "            if os.path.isfile(text_file_path):\n",
    "                with open(text_file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "                    text = file.read()\n",
    "\n",
    "                with tracing_v2_enabled():\n",
    "                    # Call the LangChain chain with the input dictionary\n",
    "                    try:\n",
    "                        result = run_chain(chain, text)\n",
    "                    except:\n",
    "                        reuslt = \"\"\n",
    "\n",
    "                # Save the result to a new file in the same subfolder\n",
    "                result_file_path = os.path.join(subfolder_path, f\"result_few_{type}.txt\")\n",
    "                with open(result_file_path, \"w\", encoding=\"utf-8\") as result_file:\n",
    "                    result_file.write(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc30d8ab-eae2-4d99-80d3-1e7bf7d5c432",
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_result_txt_files(root_folder_path):\n",
    "    \"\"\"\n",
    "    Deletes every .txt file that starts with 'result_' in the subfolders of the root folder (depth 1).\n",
    "\n",
    "    Args:\n",
    "        root_folder_path (str): Path to the root folder.\n",
    "    \"\"\"\n",
    "    for subfolder_name in os.listdir(root_folder_path):\n",
    "        subfolder_path = os.path.join(root_folder_path, subfolder_name)\n",
    "        \n",
    "        # Ensure the current item is a subfolder\n",
    "        if os.path.isdir(subfolder_path):\n",
    "            for file_name in os.listdir(subfolder_path):\n",
    "                if file_name.startswith(\"result_gpt-o3\") and file_name.endswith(\".txt\"):\n",
    "                    file_path = os.path.join(subfolder_path, file_name)\n",
    "                    os.remove(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5f5bf858-cd8f-4e3b-ae5b-629416320dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#delete_result_txt_files(ROOT_FOLDER)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c2a3d26-e23a-48a0-80c9-474784ed552c",
   "metadata": {},
   "source": [
    "# One Shot Open-AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5ae9c99e-900e-4bf1-aba7-16fe824aceee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "assert load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f9bfad1f-1c94-44db-a15a-58afc3b780ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_OPEN_AI = [\"o3-mini\", \"gpt-4o-mini\", \"gpt-4o\", \"gpt-4-turbo\", \"gpt-3.5-turbo\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "828a51ad-9e16-4eae-8c83-761db2533177",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from IPython.display import display_markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7cd398db-4102-4faa-9313-c774c7d15f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_ai_one(model):\n",
    "    model_ = ChatOpenAI(model=model)\n",
    "    chain = prompt_template | model_ | StrOutputParser()\n",
    "    process_subfolders_with_chain(ROOT_FOLDER, chain, type=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6504bdc7-44b7-4aa6-bb6b-57acd88a6ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_ai_make_example(model):\n",
    "    model = ChatOpenAI(model=model)\n",
    "    chain = prompt_template | model | StrOutputParser()\n",
    "    res = chain.invoke({\"text\": \"\"\"Alpha Insurance is an insurance company that provides its clients with various types of insurance policies. \n",
    "As soon as a customer addresses Alpha Insurance, a broker is assigned to follow the customer’s file. The broker is registered in the system, so that when a customer calls, based on the contract, the help desk can immediately trace who is the customer's first account manager. After the broker is assigned to the customer, the latter indicates which type(s) of insurance policy they would like to sign for, so the broker could, depending on the case, either assess the customer’s profile on the spot or send the customer’s file for analysis to the head office. After the customer’s profile has been assessed and the customer has been deemed trustworthy , a preliminary contract/offer on an insurance product is made to the customer either in person or by email. (Such offers can also be extended to already existing customers.) If the customer agrees to the offer, the contract is signed by both parties. After the signing of the contract, the client enjoys the coverage and is invoiced (monthly or yearly – depending on the choice made in the contract) according to the price of the insurance product they bought.\n",
    "\n",
    "In case the insured event happens, a customer should send a claim for compensation. Then the company opens one or several claim cases (e.g. in case of an accident, often material damage & physical damage are handled separately). Once the case file is complete, it is sent for assessment by different estimators based on their area of expertise. According to the reports issued by the estimators, it is decided whether the claim case is approved. In case of approval the compensation decision is registered that stipulates which costs are eligible for (partial) refund.  For the supplied documents, the sum of compensation is calculated and the compensation is paid to the customer’s account.  The estimators’ reports must be stored in the database for at least one year after the payment of compensation for legal purposes. \n",
    "\n",
    "\"\"\"})\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0233047c-8846-42bf-a24a-40e7554d0990",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "@startuml\n",
       "\n",
       "class Customer {}\n",
       "class Broker {}\n",
       "class InsurancePolicy {}\n",
       "class Contract {}\n",
       "class Invoice {}\n",
       "class ClaimCase {}\n",
       "class Estimator {}\n",
       "class Report {}\n",
       "class CompensationPayment {}\n",
       "\n",
       "Customer \"1\" -- \"0..*\" Contract\n",
       "Contract \"1\" -- \"0..*\" Invoice\n",
       "Customer \"0..1\" -- \"1\" Broker\n",
       "Broker \"1\" -- \"0..*\" InsurancePolicy\n",
       "InsurancePolicy \"1\" -- \"0..*\" Contract\n",
       "Contract \"0..*\" -- \"0..*\" ClaimCase\n",
       "ClaimCase \"0..*\" -- \"1\" Report\n",
       "Estimator \"1\" -- \"0..*\" Report\n",
       "ClaimCase \"1\" -- \"0..*\" CompensationPayment\n",
       "\n",
       "@enduml"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_markdown(open_ai_make_example(MODEL_OPEN_AI[2]), raw=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "51828f70-344d-4e2a-b442-4a4bd158f1a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Few shot with o3-mini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 48/48 [18:36<00:00, 23.26s/it]\n"
     ]
    }
   ],
   "source": [
    "for model in MODEL_OPEN_AI[0:1]:\n",
    "    print(f\"Few shot with {model}\")\n",
    "    open_ai_one(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c706969-50b8-49f0-a84c-b3ea508255df",
   "metadata": {},
   "source": [
    "## One Shot Anthropic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4f5caf72-f62c-4a43-9796-ae5bef38890e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_anthropic import ChatAnthropic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aeaba3bd-b38b-4734-9355-7f2ff06bbdc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_ANTHROPIC = [\"claude-3-7-sonnet-20250219\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1cf3440e-a67d-4472-a98a-b4310690ba90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def anthropic_make_example(model):\n",
    "    model = ChatAnthropic(model=model,temperature=0,\n",
    "    max_tokens=1024,\n",
    "    timeout=None,\n",
    "    max_retries=2,)\n",
    "    chain = prompt_template | model | StrOutputParser()\n",
    "    res = chain.invoke({\"text\": \"\"\"Alpha Insurance is an insurance company that provides its clients with various types of insurance policies. \n",
    "As soon as a customer addresses Alpha Insurance, a broker is assigned to follow the customer’s file. The broker is registered in the system, so that when a customer calls, based on the contract, the help desk can immediately trace who is the customer's first account manager. After the broker is assigned to the customer, the latter indicates which type(s) of insurance policy they would like to sign for, so the broker could, depending on the case, either assess the customer’s profile on the spot or send the customer’s file for analysis to the head office. After the customer’s profile has been assessed and the customer has been deemed trustworthy , a preliminary contract/offer on an insurance product is made to the customer either in person or by email. (Such offers can also be extended to already existing customers.) If the customer agrees to the offer, the contract is signed by both parties. After the signing of the contract, the client enjoys the coverage and is invoiced (monthly or yearly – depending on the choice made in the contract) according to the price of the insurance product they bought.\n",
    "\n",
    "In case the insured event happens, a customer should send a claim for compensation. Then the company opens one or several claim cases (e.g. in case of an accident, often material damage & physical damage are handled separately). Once the case file is complete, it is sent for assessment by different estimators based on their area of expertise. According to the reports issued by the estimators, it is decided whether the claim case is approved. In case of approval the compensation decision is registered that stipulates which costs are eligible for (partial) refund.  For the supplied documents, the sum of compensation is calculated and the compensation is paid to the customer’s account.  The estimators’ reports must be stored in the database for at least one year after the payment of compensation for legal purposes. \n",
    "\n",
    "\"\"\"})\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fba6433e-4080-4264-bd35-78096dc985e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def anthropic_one(model):\n",
    "    model_ = ChatAnthropic(model=model)\n",
    "    chain = prompt_template | model_ | StrOutputParser()\n",
    "    process_subfolders_with_chain(ROOT_FOLDER, chain, type=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f723a4ef-bab2-4376-b1cc-8a12c492d969",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "@startuml\n",
       "\n",
       "class Customer {}\n",
       "class InsurancePolicy {}\n",
       "class Contract {}\n",
       "class Invoice {}\n",
       "class Broker {}\n",
       "class ClaimCase {}\n",
       "class Report {}\n",
       "class Estimator {}\n",
       "class CompensationPayment {}\n",
       "class HeadOffice {}\n",
       "class InsuranceProduct {}\n",
       "\n",
       "Customer \"1\" -- \"0..*\" Contract\n",
       "Customer \"1\" -- \"0..*\" ClaimCase\n",
       "Broker \"1\" -- \"0..*\" Customer\n",
       "Contract \"1\" -- \"0..*\" InsurancePolicy\n",
       "Contract \"1\" -- \"0..*\" Invoice\n",
       "Contract \"1\" -- \"0..*\" InsuranceProduct\n",
       "ClaimCase \"1\" -- \"0..*\" Report\n",
       "ClaimCase \"1\" -- \"0..*\" CompensationPayment\n",
       "Estimator \"1\" -- \"0..*\" Report\n",
       "HeadOffice -- Customer\n",
       "\n",
       "@enduml"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_markdown(anthropic_make_example(MODEL_ANTHROPIC[0]), raw=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5dfc95d6-802e-46cf-ae72-1cd02e9030f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One shot with claude-3-7-sonnet-20250219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 48/48 [01:50<00:00,  2.30s/it]\n"
     ]
    }
   ],
   "source": [
    "for model in MODEL_ANTHROPIC:\n",
    "    print(f\"One shot with {model}\")\n",
    "    anthropic_one(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d878307c-cf11-4ff0-9a16-2ca8b6ea7a72",
   "metadata": {},
   "source": [
    "# One Shot Open LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f1a07202-45d1-40b5-8985-fcb10cb05c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, gc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e082082-beff-4af3-87ca-21a0256c1bac",
   "metadata": {},
   "source": [
    "## Deepseek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9f35dc70-517c-4b86-a918-48cc46e25275",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_deepseek import ChatDeepSeek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "00aa4f23-9563-4072-87cf-606994e76909",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_DEEPSEEK = [\"deepseek-chat\"] #, \"deepseek-reasoner\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b51ccb2f-58a9-443d-be56-fcb7d560ce5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def deepseek_make_example(model):\n",
    "    model = llm = ChatDeepSeek(\n",
    "            model=model,\n",
    "            temperature=0,\n",
    "            max_tokens=None,\n",
    "            timeout=None,\n",
    "            max_retries=2,\n",
    "            # api_key=\"...\",\n",
    "            # other params...\n",
    "        )\n",
    "    chain = prompt_template | model | StrOutputParser()\n",
    "    res = chain.invoke({\"text\": \"\"\"Alpha Insurance is an insurance company that provides its clients with various types of insurance policies. \n",
    "As soon as a customer addresses Alpha Insurance, a broker is assigned to follow the customer’s file. The broker is registered in the system, so that when a customer calls, based on the contract, the help desk can immediately trace who is the customer's first account manager. After the broker is assigned to the customer, the latter indicates which type(s) of insurance policy they would like to sign for, so the broker could, depending on the case, either assess the customer’s profile on the spot or send the customer’s file for analysis to the head office. After the customer’s profile has been assessed and the customer has been deemed trustworthy , a preliminary contract/offer on an insurance product is made to the customer either in person or by email. (Such offers can also be extended to already existing customers.) If the customer agrees to the offer, the contract is signed by both parties. After the signing of the contract, the client enjoys the coverage and is invoiced (monthly or yearly – depending on the choice made in the contract) according to the price of the insurance product they bought.\n",
    "\n",
    "In case the insured event happens, a customer should send a claim for compensation. Then the company opens one or several claim cases (e.g. in case of an accident, often material damage & physical damage are handled separately). Once the case file is complete, it is sent for assessment by different estimators based on their area of expertise. According to the reports issued by the estimators, it is decided whether the claim case is approved. In case of approval the compensation decision is registered that stipulates which costs are eligible for (partial) refund.  For the supplied documents, the sum of compensation is calculated and the compensation is paid to the customer’s account.  The estimators’ reports must be stored in the database for at least one year after the payment of compensation for legal purposes. \n",
    "\n",
    "\"\"\"})\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0d4500e8-ae1d-405e-b6b5-01afe4bca913",
   "metadata": {},
   "outputs": [],
   "source": [
    "def deepseek_one(model):\n",
    "    model_ = ChatDeepSeek(model=model)\n",
    "    chain = prompt_template | model_ | StrOutputParser()\n",
    "    process_subfolders_with_chain(ROOT_FOLDER, chain, type=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "15cba5b2-896b-421d-af9d-21ae608ee82e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "@startuml\n",
       "\n",
       "class Customer {}\n",
       "class InsurancePolicy {}\n",
       "class Contract {}\n",
       "class Invoice {}\n",
       "class BrokerCustomerAssignment {}\n",
       "class Broker {}\n",
       "class ClaimCase {}\n",
       "class Report {}\n",
       "class Estimator {}\n",
       "class CompensationPayment {}\n",
       "\n",
       "Contract \"0..*\" -- \"1\" Customer\n",
       "Contract \"1\" -- \"0..*\" Invoice\n",
       "Contract \"1\" -- \"0..*\" InsurancePolicy\n",
       "Contract \"1\" -- \"0..*\" ClaimCase\n",
       "\n",
       "ClaimCase \"1\" -- \"0..*\" CompensationPayment\n",
       "ClaimCase \"1\" -- \"0..*\" Report\n",
       "Report \"0..*\" -- \"1\" Estimator\n",
       "BrokerCustomerAssignment \"0..1\" -- \"1\" Customer\n",
       "Broker \"1\" -- \"0..*\" BrokerCustomerAssignment\n",
       "\n",
       "@enduml"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 108 ms, sys: 10.5 ms, total: 119 ms\n",
      "Wall time: 11.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "display_markdown(deepseek_make_example(MODEL_DEEPSEEK[0]), raw=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0c28832d-09cb-4adb-9483-2b7e0d5ea23a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One shot with deepseek-chat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 48/48 [06:24<00:00,  8.01s/it]\n"
     ]
    }
   ],
   "source": [
    "for model in MODEL_DEEPSEEK:\n",
    "    print(f\"One shot with {model}\")\n",
    "    deepseek_one(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e30f2b7-0eb2-465a-9224-98a42a171fe0",
   "metadata": {},
   "source": [
    "## Ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "848047d5-35d6-4272-9ba4-a1e6a39346bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6ce832ba-b152-4775-87cd-c69565f67b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_OLLAMA = [] #[\"llama3.2:3b-text-fp16\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "df4335f3-03a9-45af-8d82-bba70439807a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ollama_one(model):\n",
    "    model_ = ChatOllama(\n",
    "        model=model,\n",
    "        temperature=0,\n",
    "        timeout = 3,\n",
    "    )\n",
    "    chain = prompt_template | model_ | StrOutputParser()\n",
    "    process_subfolders_with_chain(ROOT_FOLDER, chain, type=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0477e649-cfda-4654-a52c-c58940935865",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ollama_make_example(model):\n",
    "    model = ChatOllama(\n",
    "        model=model,\n",
    "        temperature=0,\n",
    "        timeout = 3,\n",
    "    )\n",
    "    chain = prompt_template | model | StrOutputParser()\n",
    "    res = chain.invoke({\"text\": \"\"\"Alpha Insurance is an insurance company that provides its clients with various types of insurance policies. \n",
    "As soon as a customer addresses Alpha Insurance, a broker is assigned to follow the customer’s file. The broker is registered in the system, so that when a customer calls, based on the contract, the help desk can immediately trace who is the customer's first account manager. After the broker is assigned to the customer, the latter indicates which type(s) of insurance policy they would like to sign for, so the broker could, depending on the case, either assess the customer’s profile on the spot or send the customer’s file for analysis to the head office. After the customer’s profile has been assessed and the customer has been deemed trustworthy , a preliminary contract/offer on an insurance product is made to the customer either in person or by email. (Such offers can also be extended to already existing customers.) If the customer agrees to the offer, the contract is signed by both parties. After the signing of the contract, the client enjoys the coverage and is invoiced (monthly or yearly – depending on the choice made in the contract) according to the price of the insurance product they bought.\n",
    "\n",
    "In case the insured event happens, a customer should send a claim for compensation. Then the company opens one or several claim cases (e.g. in case of an accident, often material damage & physical damage are handled separately). Once the case file is complete, it is sent for assessment by different estimators based on their area of expertise. According to the reports issued by the estimators, it is decided whether the claim case is approved. In case of approval the compensation decision is registered that stipulates which costs are eligible for (partial) refund.  For the supplied documents, the sum of compensation is calculated and the compensation is paid to the customer’s account.  The estimators’ reports must be stored in the database for at least one year after the payment of compensation for legal purposes. \n",
    "\n",
    "\"\"\"})\n",
    "    return res\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "33afa71e-b8c6-4c49-b11b-b89cfb704409",
   "metadata": {},
   "outputs": [],
   "source": [
    "#display_markdown(ollama_make_example(MODEL_OLLAMA[0]), raw=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "48b60c86-7d08-4790-b5ae-b875c102788e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in MODEL_OLLAMA:\n",
    "    print(f\"Zero shot with {model}\")\n",
    "    ollama_one(model)\n",
    "    gc.collect()\n",
    "    torch.mps.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db448981-cf0a-42b5-b7ed-cb73bf0fbb56",
   "metadata": {},
   "source": [
    "## Huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "96994dbd-a971-4ae7-9ee9-5d0705d9a2ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface import HuggingFacePipeline, ChatHuggingFace, HuggingFaceEndpoint\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b07eead8-de14-4dc8-95bf-02c77101f9dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_HUGGINGFACE = [] #[\"Qwen/Qwen2.5-3B-Instruct\", \"microsoft/Phi-3-mini-4k-instruct\", \"google/gemma-2-27b-it\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ccce77e7-20f7-45b0-817b-b04107541a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def huggingface_one(model):\n",
    "    model_id = model\n",
    "    \n",
    "    llm = HuggingFaceEndpoint(\n",
    "        repo_id=model_id,\n",
    "        task=\"text-generation\",\n",
    "        max_new_tokens=2048,\n",
    "        do_sample=False,\n",
    "        repetition_penalty=1.03,\n",
    "        temperature=0.01)\n",
    "\n",
    "    chat = ChatHuggingFace(llm=llm, verbose=True)\n",
    "    \n",
    "    chain = prompt_template | chat | StrOutputParser()\n",
    "    process_subfolders_with_chain(ROOT_FOLDER, chain, type=model_id.replace(\"/\",\"_\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a8cab307-e878-41a6-a13d-0f6904a4f30c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def huggingface_make_example(model):\n",
    "\n",
    "    model_id = model\n",
    "    \n",
    "    \n",
    "\n",
    "    llm = HuggingFacePipeline.from_model_id(\n",
    "        model_id=model_id,\n",
    "        task=\"text-generation\",\n",
    "        pipeline_kwargs={\"temperature\": 0.1, \"max_new_tokens\": 1024}\n",
    "    )\n",
    "\n",
    "    chat = ChatHuggingFace(llm=llm, verbose=True)\n",
    "    \n",
    "    chain = prompt_template | chat | StrOutputParser()\n",
    "    res = chain.invoke({\"text\": \"\"\"Alpha Insurance is an insurance company that provides its clients with various types of insurance policies. \n",
    "        As soon as a customer addresses Alpha Insurance, a broker is assigned to follow the customer’s file. The broker is registered in the system, so that when a customer calls, based on the contract, the help desk can immediately trace who is the customer's first account manager. After the broker is assigned to the customer, the latter indicates which type(s) of insurance policy they would like to sign for, so the broker could, depending on the case, either assess the customer’s profile on the spot or send the customer’s file for analysis to the head office. After the customer’s profile has been assessed and the customer has been deemed trustworthy , a preliminary contract/offer on an insurance product is made to the customer either in person or by email. (Such offers can also be extended to already existing customers.) If the customer agrees to the offer, the contract is signed by both parties. After the signing of the contract, the client enjoys the coverage and is invoiced (monthly or yearly – depending on the choice made in the contract) according to the price of the insurance product they bought.\n",
    "        \n",
    "        In case the insured event happens, a customer should send a claim for compensation. Then the company opens one or several claim cases (e.g. in case of an accident, often material damage & physical damage are handled separately). Once the case file is complete, it is sent for assessment by different estimators based on their area of expertise. According to the reports issued by the estimators, it is decided whether the claim case is approved. In case of approval the compensation decision is registered that stipulates which costs are eligible for (partial) refund.  For the supplied documents, the sum of compensation is calculated and the compensation is paid to the customer’s account.  The estimators’ reports must be stored in the database for at least one year after the payment of compensation for legal purposes. \n",
    "        \n",
    "        \"\"\"})\n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6cfe2884-9b34-4874-ae95-9985e4a09870",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#display_markdown(huggingface_make_example(MODEL_HUGGINGFACE[0]), raw=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ba9b628f-024e-450a-8d85-2db5b0c67c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in MODEL_HUGGINGFACE:\n",
    "    print(f\"Zero shot with {model}\")\n",
    "    huggingface_one(model)\n",
    "    gc.collect()\n",
    "    torch.mps.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e76f5762-513f-4c2d-93f8-10598a2e7827",
   "metadata": {},
   "source": [
    "## Mlx-LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a61c5ea0-0f4a-4cc2-8220-0d38d8f91bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.llms import MLXPipeline\n",
    "from langchain_community.chat_models import ChatMLX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6c805336-ba69-459f-9fd9-3271aeec6aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_MLX = [\"mlx-community/phi-4-8bit\",\n",
    "             \"mlx-community/Falcon3-10B-Instruct-8bit\", \n",
    "             \"mlx-community/Qwen2.5-14B-Instruct-4bit\",\n",
    "             \"mlx-community/Mistral-7B-Instruct-v0.3-4bit\",\n",
    "             \"mlx-community/DeepSeek-R1-Distill-Qwen-7B-8bit\",\n",
    "             \"mlx-community/Llama-3.2-3B-Instruct\",\n",
    "             \"mlx-community/gemma-2-9b-8bit\",\n",
    "             #\"mlx-community/gemma-2-27b-it-4bit\",\n",
    "            # \"mlx-community/Mamba-Codestral-7B-v0.1-8bit\",\n",
    "            #\"mlx-community/CodeLlama-13b-Instruct-hf-4bit-MLX\"\n",
    "            ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "958151bc-0e7e-418a-9127-98d1e00e558b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlx_one(model):\n",
    "    llm = MLXPipeline.from_model_id(\n",
    "        model_id=model,\n",
    "        pipeline_kwargs={\"max_tokens\": 15_000, \"temp\": 0.1},\n",
    "    )\n",
    "    chat = ChatMLX(llm=llm)\n",
    "    chain = prompt_template | chat | StrOutputParser()\n",
    "    process_subfolders_with_chain(ROOT_FOLDER, chain, type=model.replace(\"/\",\"_\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "68a8ee38-7b7b-4a1f-8dec-02cb504b53b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlx_make_example(model):\n",
    "    llm = MLXPipeline.from_model_id(\n",
    "        model_id=model,\n",
    "        pipeline_kwargs={\"max_tokens\": 2000, \"temp\": 0.7},\n",
    "    )\n",
    "    chat = ChatMLX(llm=llm)\n",
    "    chain = prompt_template | chat | StrOutputParser()\n",
    "    res = chain.invoke({\"text\": \"\"\"Alpha Insurance is an insurance company that provides its clients with various types of insurance policies. \n",
    "As soon as a customer addresses Alpha Insurance, a broker is assigned to follow the customer’s file. The broker is registered in the system, so that when a customer calls, based on the contract, the help desk can immediately trace who is the customer's first account manager. After the broker is assigned to the customer, the latter indicates which type(s) of insurance policy they would like to sign for, so the broker could, depending on the case, either assess the customer’s profile on the spot or send the customer’s file for analysis to the head office. After the customer’s profile has been assessed and the customer has been deemed trustworthy , a preliminary contract/offer on an insurance product is made to the customer either in person or by email. (Such offers can also be extended to already existing customers.) If the customer agrees to the offer, the contract is signed by both parties. After the signing of the contract, the client enjoys the coverage and is invoiced (monthly or yearly – depending on the choice made in the contract) according to the price of the insurance product they bought.\n",
    "\n",
    "In case the insured event happens, a customer should send a claim for compensation. Then the company opens one or several claim cases (e.g. in case of an accident, often material damage & physical damage are handled separately). Once the case file is complete, it is sent for assessment by different estimators based on their area of expertise. According to the reports issued by the estimators, it is decided whether the claim case is approved. In case of approval the compensation decision is registered that stipulates which costs are eligible for (partial) refund.  For the supplied documents, the sum of compensation is calculated and the compensation is paid to the customer’s account.  The estimators’ reports must be stored in the database for at least one year after the payment of compensation for legal purposes. \n",
    "\n",
    "\"\"\"})\n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "30a9e5a1-d9a8-447f-877e-645a04c5d2e4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a03d05eb19b5420fae34cdd22ae00a68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 10 files:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "@startuml\n",
       "\n",
       "class Customer {}\n",
       "class InsurancePolicy {}\n",
       "class Contract {}\n",
       "class Invoice {}\n",
       "class BrokerCustomerAssignment {}\n",
       "class Broker {}\n",
       "class ClaimCase {}\n",
       "class Report {}\n",
       "class Estimator {}\n",
       "class CompensationPayment {}\n",
       "\n",
       "Customer \"0..*\" -- \"1\" Contract\n",
       "Contract \"1\" -- \"0..*\" Invoice\n",
       "Contract \"0..*\" -- \"1\" BrokerCustomerAssignment\n",
       "BrokerCustomerAssignment \"1\" -- \"1\" Broker\n",
       "Contract \"1\" -- \"0..*\" InsurancePolicy\n",
       "Contract \"1\" -- \"0..*\" ClaimCase\n",
       "ClaimCase \"1\" -- \"0..*\" CompensationPayment\n",
       "ClaimCase \"1\" -- \"0..*\" Report\n",
       "Report \"0..*\" -- \"1\" Estimator\n",
       "\n",
       "@enduml"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_markdown(mlx_make_example(MODEL_MLX[2]), raw=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ccea0873-879d-4fcb-a1a0-d97197370751",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION\"] = \"python\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "5d835f1b-7493-4a1b-8c51-26142777d17d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Few shot with mlx-community/Llama-3.2-3B-Instruct\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6256212c10a545b4b18034cea2f6efbb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 7 files:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 44/44 [04:29<00:00,  6.12s/it]\n"
     ]
    }
   ],
   "source": [
    "for model in MODEL_MLX:\n",
    "    print(f\"Few shot with {model}\")\n",
    "    mlx_one(model)\n",
    "    import gc, torch\n",
    "    gc.collect()\n",
    "    torch.mps.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0067e756-9fdc-4a62-9aef-70ac6df19f12",
   "metadata": {},
   "source": [
    "### Clean Cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c3904bc0-b746-400e-b5f0-4988b10d459e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc, torch\n",
    "gc.collect()\n",
    "torch.mps.empty_cache()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
